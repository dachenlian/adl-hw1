{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "better-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noticed-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "from itertools import chain\n",
    "import logging\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "from seqeval.metrics import classification_report, accuracy_score, f1_score\n",
    "from seqeval.scheme import IOB2\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "resistant-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "developmental-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_glove(fpath: str, save=True, save_path='../../data/glove.840B.300d.gz') -> Dict[str, np.array]:\n",
    "    logger.info(\"Loading Glove embeddings...\")\n",
    "    glove = {}\n",
    "    with open(fpath) as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = ''.join(values[:-300])\n",
    "            vector = np.array([float(v) for v in values[-300:]])\n",
    "            glove[word] = vector\n",
    "            \n",
    "    logger.info(\"GloVe embeddings loaded.\")\n",
    "    if save:\n",
    "        logger.info(\"Saving GloVe to disk.\")\n",
    "        with gzip.open(save_path, 'wb') as f:\n",
    "            pickle.dump(glove, f)\n",
    "        logger.info(\"Save complete.\")\n",
    "    return glove\n",
    "\n",
    "def build_mapping(fpath: str, key: str, save_path: str):\n",
    "    with open(fpath) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "#     labels = list(set([*i[key] if isinstance(i[key], list) else i[key] for i in data]))\n",
    "    labels = []\n",
    "    for sample in data:\n",
    "        label = sample[key]\n",
    "        if isinstance(label, list):\n",
    "            labels.extend(label)\n",
    "        else:\n",
    "            labels.append(label)\n",
    "    labels = list(set(labels))\n",
    "    labels_to_idx = {label: idx for idx, label in enumerate(labels)}  \n",
    "    \n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(labels_to_idx, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    return labels_to_idx\n",
    "\n",
    "    \n",
    "def write_preds_to_csv(task: str, ids: list, preds: list, fname: str = \"intent_preds.csv\"):\n",
    "    fpath = \"../ADL21-HW1/data/intent/\" + fname\n",
    "    if task == 'tagging':\n",
    "        header = ['id', 'tags']\n",
    "        out = {}\n",
    "        for _id, pred in zip(ids, preds):\n",
    "            out[_id] = out.get(_id, list())\n",
    "            out[_id].append(pred)\n",
    "        out = {key: \" \".join(val) for key, val in out.items()}\n",
    "            \n",
    "        \n",
    "    elif task == 'intent':\n",
    "        header = ['id', 'intent']\n",
    "        \n",
    "    with open(fpath, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        if task == 'tagging':\n",
    "            writer.writerows(out.items())\n",
    "        elif task == 'intent':\n",
    "            writer.writerows(zip(ids, preds))\n",
    "    logger.info(f\"Intent predictions written to {fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "passing-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "handled-standing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('$',\n",
       " \"''\",\n",
       " ',',\n",
       " '-LRB-',\n",
       " '-RRB-',\n",
       " '.',\n",
       " ':',\n",
       " 'ADD',\n",
       " 'AFX',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'FW',\n",
       " 'HYPH',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'LS',\n",
       " 'MD',\n",
       " 'NFP',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNPS',\n",
       " 'NNS',\n",
       " 'PDT',\n",
       " 'POS',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'SYM',\n",
       " 'TO',\n",
       " 'UH',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'WRB',\n",
       " 'XX',\n",
       " '``')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.get_pipe('tagger').labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-nursing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-14 21:35:34,953 - __main__ - INFO - Loading Glove embeddings...\n",
      "2021-04-14 21:38:30,555 - __main__ - INFO - GloVe embeddings loaded.\n",
      "2021-04-14 21:38:30,556 - __main__ - INFO - Saving GloVe to disk.\n",
      "2021-04-14 21:42:19,358 - __main__ - INFO - Save complete.\n"
     ]
    }
   ],
   "source": [
    "# glove = build_glove('../../data/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nervous-windows",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build_intent_mappings('../ADL21-HW1/data/intent/train.json', save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-disco",
   "metadata": {},
   "source": [
    "# Intent Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-twist",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spiritual-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, data_path: str, train: bool, device: str, intent_mapping: Dict[str, int], glove: Optional[Dict[str, np.array]] = None, glove_path: str = \"../../data/glove.840B.300d.pkl.gz\", unk_token_strategy='ignore'):\n",
    "        with open(data_path) as f: \n",
    "            self.data = json.load(f)\n",
    "        self.intent_to_idx = intent_mapping\n",
    "        self.device = device\n",
    "        self.train = train\n",
    "        self.glove = glove\n",
    "        self.tokenizer = English().tokenizer\n",
    "        self.unk_token_strategy = unk_token_strategy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        _id = sample['id']\n",
    "        text = sample['text']\n",
    "        text = self.convert_to_vectors(text)\n",
    "        length = len(text)\n",
    "        out = {\n",
    "            'id': _id,\n",
    "            'text': text,\n",
    "            'length': length\n",
    "        }\n",
    "        if self.train:\n",
    "            intent = sample['intent']\n",
    "            intent = self.intent_to_idx[intent]\n",
    "            out['intent'] = intent\n",
    "        return out\n",
    "        \n",
    "    def convert_to_vectors(self, text):\n",
    "        vectors = []\n",
    "        if self.unk_token_strategy == 'ignore':\n",
    "            for idx, tok in enumerate(self.tokenizer(text)):\n",
    "                try:\n",
    "#                     vector = self.glove[tok.text].to(self.device)\n",
    "                    vector = torch.from_numpy(self.glove[tok.text]).float()\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                else:\n",
    "                    vectors.append(vector)\n",
    "        return torch.stack(vectors)\n",
    "            \n",
    "        \n",
    "class IntentDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, device: str, data_dir: str = \"../ADL21-HW1/data/intent\", intent_mapping: str = \"../data/intents_to_idx.json\", embedding_obj: Optional[Dict[str, np.array]] = None, embedding_dir: str = \"../../data/glove.840B.300d.gz\", batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.batch_size = batch_size\n",
    "        with open(intent_mapping) as f:\n",
    "            self.intent_to_idx = json.load(f)\n",
    "        if embedding_obj:\n",
    "            self.emb = embedding_obj\n",
    "        else:\n",
    "            self.emb = self._load_glove(embedding_dir)\n",
    "        \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.intent_train = IntentDataset(\n",
    "                device=self.device,\n",
    "                data_path=self.data_dir.joinpath('train.json'), \n",
    "                train=True,\n",
    "                intent_mapping=self.intent_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "            self.intent_val = IntentDataset(\n",
    "                device=self.device,\n",
    "                data_path=self.data_dir.joinpath('eval.json'), \n",
    "                train=True,\n",
    "                intent_mapping=self.intent_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "        elif stage == \"test\" or stage is None:\n",
    "            self.intent_test = IntentDataset(\n",
    "                device=self.device,\n",
    "                data_path=self.data_dir.joinpath('test.json'), \n",
    "                train=False,\n",
    "                intent_mapping=self.intent_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.intent_train, batch_size=self.batch_size, num_workers=8, pin_memory=True, collate_fn=self._collate_fn(False), shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.intent_val, batch_size=self.batch_size, num_workers=8, pin_memory=True, collate_fn=self._collate_fn(False))\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.intent_test, batch_size=self.batch_size, num_workers=8, pin_memory=True, collate_fn=self._collate_fn(True))\n",
    "        \n",
    "    @staticmethod\n",
    "    def _collate_fn(is_test):\n",
    "        def collate_fn(batch):\n",
    "            out = {}\n",
    "            _id = [b['id'] for b in batch]\n",
    "            text = [b['text'] for b in batch]\n",
    "            length = torch.LongTensor([b['length'] for b in batch])\n",
    "            text = pad_sequence(text, batch_first=True)\n",
    "            if not is_test:\n",
    "                intent = torch.LongTensor([b['intent'] for b in batch])\n",
    "                out['intent'] = intent\n",
    "\n",
    "            out['id'] = _id\n",
    "            out['text'] = text\n",
    "            out['length'] = length\n",
    "            out['text'] = text\n",
    "            return out\n",
    "        return collate_fn\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_glove(fpath: str) -> Dict[str, torch.FloatTensor]:\n",
    "        logger.info(\"Loading GloVe embeddings...\")\n",
    "        with gzip.open(fpath, 'rb') as f:\n",
    "            emb = pickle.load(f)\n",
    "        logger.info(\"Done!\")\n",
    "        return emb\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-midnight",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "provincial-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_labels: int, hidden_size: int = 128, num_layers: int = 3, bidirectional: bool = True, lr: int = 1e-4, dropout=0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = 2 if bidirectional else 1\n",
    "        self.lr = lr\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=300, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=bidirectional, \n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.hidden_to_labels = nn.Linear(self.hidden_size * self.bidirectional, num_labels)\n",
    "        self.save_hyperparameters()\n",
    "        self.test_preds = {\n",
    "            'ids': [],\n",
    "            'logits': []\n",
    "        }\n",
    "        \n",
    "    def forward(self, inpt):\n",
    "        samples = inpt['text']\n",
    "        lengths = inpt['length'].to('cpu')\n",
    "        batch_size = samples.shape[0]\n",
    "        samples = pack_padded_sequence(samples, lengths, batch_first=True, enforce_sorted=False)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(samples, hidden)\n",
    "        hidden = torch.cat([hidden[-1,...], hidden[-2,...]], dim=1)  # concat last hidden states of forwards and backwards\n",
    "        logits = self.hidden_to_labels(hidden)\n",
    "        return logits\n",
    "        \n",
    "    def _shared_step(self, batch):\n",
    "        ids = batch['id']\n",
    "        intent = batch['intent']\n",
    "        logits = self(batch)\n",
    "        loss = F.nll_loss(F.log_softmax(logits, dim=1), intent)\n",
    "        return loss\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self.log('training_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids = batch['id']\n",
    "        logits = self(batch)\n",
    "        self.test_preds['ids'].extend(ids)\n",
    "        self.test_preds['logits'].extend(logits)\n",
    "        \n",
    "    \n",
    "    def process_logits(self, logits, idx2int):\n",
    "        preds = torch.stack(logits)\n",
    "        preds = preds.argmax(dim=1).tolist()\n",
    "        preds = [idx2int[p] for p in preds]\n",
    "        return preds\n",
    "            \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.normal(mean=0, std=1, size=(self.bidirectional * self.num_layers, batch_size, self.hidden_size)).to('cuda')\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-budapest",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "enormous-camping",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IntentDataModule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-38a77b99afec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntentDataModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/glove.840B.300d.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'IntentDataModule' is not defined"
     ]
    }
   ],
   "source": [
    "# glove = IntentDataModule._load_glove('../../data/glove.840B.300d.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "inappropriate-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_dm = IntentDataModule(device=device, embedding_obj=glove)\n",
    "intent_labels = intent_dm.intent_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "stainless-italy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intent_dm.prepare_data()\n",
    "intent_dm.setup('fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "healthy-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(intent_dm.intent_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "cloudy-local",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'train-0',\n",
       " 'text': tensor([[ 0.1873,  0.4060, -0.5117,  ...,  0.1649,  0.1876,  0.5387],\n",
       "         [ 0.1206,  0.1426, -0.1558,  ..., -0.3866,  0.0566,  0.0155],\n",
       "         [-0.1108,  0.3079, -0.5198,  ..., -0.0591,  0.4760,  0.0566],\n",
       "         ...,\n",
       "         [-0.2323,  0.4963,  0.3955,  ..., -0.3698, -0.2552,  0.2159],\n",
       "         [-0.0702,  0.1527, -0.3309,  ..., -0.1373,  0.1575,  0.6155],\n",
       "         [ 0.2123,  0.1944,  0.7883,  ...,  0.1774, -0.7119, -0.3592]]),\n",
       " 'length': 15,\n",
       " 'intent': 14}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "broken-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IntentClassifier(num_labels=len(intent_labels), hidden_size=256, dropout=0.5)\n",
    "# model = IntentClassifier.load_from_checkpoint(\"./lightning_logs/version_67/checkpoints/epoch=17-step=8441.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "frozen-botswana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "#     auto_lr_find=True,\n",
    "    gpus=1,\n",
    "    gradient_clip_val=1,\n",
    "    weights_summary='full',\n",
    "#     track_grad_norm=2,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss')],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "valuable-breach",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type   | Params\n",
      "--------------------------------------------\n",
      "0 | rnn              | GRU    | 3.2 M \n",
      "1 | hidden_to_labels | Linear | 77.0 K\n",
      "--------------------------------------------\n",
      "3.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 M     Total params\n",
      "13.198    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|████████▎ | 470/563 [00:14<00:02, 33.17it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 476/563 [00:15<00:02, 31.49it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Epoch 0:  86%|████████▌ | 484/563 [00:15<00:02, 31.79it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Epoch 0:  88%|████████▊ | 496/563 [00:15<00:02, 32.36it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Epoch 0:  90%|█████████ | 508/563 [00:15<00:01, 32.90it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Validating:  43%|████▎     | 40/94 [00:01<00:00, 54.98it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 520/563 [00:15<00:01, 33.32it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Epoch 0:  94%|█████████▍| 532/563 [00:15<00:00, 33.72it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Validating:  70%|███████   | 66/94 [00:01<00:00, 64.72it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 544/563 [00:15<00:00, 34.13it/s, loss=4.66, v_num=70, val_loss_epoch=4.990, training_loss_step=4.590]\n",
      "Epoch 0: 100%|██████████| 563/563 [00:16<00:00, 34.39it/s, loss=4.66, v_num=70, val_loss_epoch=4.600, training_loss_step=4.620, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Epoch 1:  83%|████████▎ | 469/563 [00:13<00:02, 35.27it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 480/563 [00:14<00:02, 33.50it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Validating:  14%|█▍        | 13/94 [00:00<00:04, 17.70it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 492/563 [00:14<00:02, 33.96it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Epoch 1:  90%|████████▉ | 504/563 [00:14<00:01, 34.41it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Validating:  40%|████      | 38/94 [00:01<00:01, 45.49it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 516/563 [00:14<00:01, 34.80it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Epoch 1:  94%|█████████▍| 528/563 [00:14<00:00, 35.36it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Epoch 1:  96%|█████████▌| 540/563 [00:15<00:00, 35.83it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Epoch 1:  98%|█████████▊| 552/563 [00:15<00:00, 36.21it/s, loss=3.29, v_num=70, val_loss_epoch=4.600, training_loss_step=3.080, training_loss_epoch=4.930, val_loss_step=4.600]\n",
      "Validating:  91%|█████████▏| 86/94 [00:01<00:00, 71.81it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 563/563 [00:15<00:00, 35.82it/s, loss=3.29, v_num=70, val_loss_epoch=3.270, training_loss_step=3.180, training_loss_epoch=3.950, val_loss_step=3.300]\n",
      "Epoch 2:  83%|████████▎ | 469/563 [00:13<00:02, 33.63it/s, loss=2.3, v_num=70, val_loss_epoch=3.270, training_loss_step=2.240, training_loss_epoch=3.950, val_loss_step=3.300] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:20,  1.15it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 480/563 [00:15<00:02, 31.94it/s, loss=2.3, v_num=70, val_loss_epoch=3.270, training_loss_step=2.240, training_loss_epoch=3.950, val_loss_step=3.300]\n",
      "Epoch 2:  87%|████████▋ | 492/563 [00:15<00:02, 32.51it/s, loss=2.3, v_num=70, val_loss_epoch=3.270, training_loss_step=2.240, training_loss_epoch=3.950, val_loss_step=3.300]\n",
      "Epoch 2:  90%|████████▉ | 505/563 [00:15<00:01, 33.15it/s, loss=2.3, v_num=70, val_loss_epoch=3.270, training_loss_step=2.240, training_loss_epoch=3.950, val_loss_step=3.300]\n",
      "Epoch 2:  92%|█████████▏| 518/563 [00:15<00:01, 33.61it/s, loss=2.3, v_num=70, val_loss_epoch=3.270, training_loss_step=2.240, training_loss_epoch=3.950, val_loss_step=3.300]\n",
      "Epoch 2:  94%|█████████▍| 531/563 [00:15<00:00, 34.04it/s, loss=2.3, v_num=70, val_loss_epoch=3.270, training_loss_step=2.240, training_loss_epoch=3.950, val_loss_step=3.300]\n",
      "Validating:  66%|██████▌   | 62/94 [00:01<00:00, 62.38it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 544/563 [00:15<00:00, 34.49it/s, loss=2.3, v_num=70, val_loss_epoch=3.270, training_loss_step=2.240, training_loss_epoch=3.950, val_loss_step=3.300]\n",
      "Epoch 2: 100%|██████████| 563/563 [00:16<00:00, 34.76it/s, loss=2.3, v_num=70, val_loss_epoch=2.340, training_loss_step=2.040, training_loss_epoch=2.760, val_loss_step=2.230]\n",
      "Epoch 3:  83%|████████▎ | 469/563 [00:13<00:02, 34.63it/s, loss=1.72, v_num=70, val_loss_epoch=2.340, training_loss_step=1.750, training_loss_epoch=2.760, val_loss_step=2.230]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:25,  1.09it/s]\u001b[A\n",
      "Validating:   9%|▊         | 8/94 [00:01<00:08, 10.31it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 486/563 [00:14<00:02, 32.93it/s, loss=1.72, v_num=70, val_loss_epoch=2.340, training_loss_step=1.750, training_loss_epoch=2.760, val_loss_step=2.230]\n",
      "Epoch 3:  90%|████████▉ | 504/563 [00:14<00:01, 33.82it/s, loss=1.72, v_num=70, val_loss_epoch=2.340, training_loss_step=1.750, training_loss_epoch=2.760, val_loss_step=2.230]\n",
      "Validating:  45%|████▍     | 42/94 [00:01<00:00, 59.16it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 522/563 [00:15<00:01, 34.56it/s, loss=1.72, v_num=70, val_loss_epoch=2.340, training_loss_step=1.750, training_loss_epoch=2.760, val_loss_step=2.230]\n",
      "Validating:  65%|██████▍   | 61/94 [00:01<00:00, 65.61it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 540/563 [00:15<00:00, 35.16it/s, loss=1.72, v_num=70, val_loss_epoch=2.340, training_loss_step=1.750, training_loss_epoch=2.760, val_loss_step=2.230]\n",
      "Epoch 3: 100%|██████████| 563/563 [00:15<00:00, 35.42it/s, loss=1.72, v_num=70, val_loss_epoch=1.800, training_loss_step=1.410, training_loss_epoch=1.980, val_loss_step=1.560]\n",
      "Epoch 4:  83%|████████▎ | 469/563 [00:13<00:02, 34.52it/s, loss=1.36, v_num=70, val_loss_epoch=1.800, training_loss_step=1.580, training_loss_epoch=1.980, val_loss_step=1.560]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:22,  1.12it/s]\u001b[A\n",
      "Validating:   9%|▊         | 8/94 [00:00<00:08, 10.56it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 486/563 [00:14<00:02, 32.89it/s, loss=1.36, v_num=70, val_loss_epoch=1.800, training_loss_step=1.580, training_loss_epoch=1.980, val_loss_step=1.560]\n",
      "Validating:  26%|██▌       | 24/94 [00:01<00:02, 32.46it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 504/563 [00:15<00:01, 33.56it/s, loss=1.36, v_num=70, val_loss_epoch=1.800, training_loss_step=1.580, training_loss_epoch=1.980, val_loss_step=1.560]\n",
      "Epoch 4:  93%|█████████▎| 522/563 [00:15<00:01, 34.35it/s, loss=1.36, v_num=70, val_loss_epoch=1.800, training_loss_step=1.580, training_loss_epoch=1.980, val_loss_step=1.560]\n",
      "Validating:  56%|█████▋    | 53/94 [00:01<00:00, 68.14it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 540/563 [00:15<00:00, 35.20it/s, loss=1.36, v_num=70, val_loss_epoch=1.800, training_loss_step=1.580, training_loss_epoch=1.980, val_loss_step=1.560]\n",
      "Epoch 4:  99%|█████████▉| 558/563 [00:15<00:00, 35.83it/s, loss=1.36, v_num=70, val_loss_epoch=1.800, training_loss_step=1.580, training_loss_epoch=1.980, val_loss_step=1.560]\n",
      "Epoch 4: 100%|██████████| 563/563 [00:15<00:00, 35.26it/s, loss=1.36, v_num=70, val_loss_epoch=1.410, training_loss_step=1.330, training_loss_epoch=1.490, val_loss_step=1.050]\n",
      "Epoch 5:  83%|████████▎ | 469/563 [00:13<00:02, 33.85it/s, loss=1.1, v_num=70, val_loss_epoch=1.410, training_loss_step=1.220, training_loss_epoch=1.490, val_loss_step=1.050] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:20,  1.16it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 486/563 [00:14<00:02, 32.50it/s, loss=1.1, v_num=70, val_loss_epoch=1.410, training_loss_step=1.220, training_loss_epoch=1.490, val_loss_step=1.050]\n",
      "Epoch 5:  90%|████████▉ | 504/563 [00:15<00:01, 33.40it/s, loss=1.1, v_num=70, val_loss_epoch=1.410, training_loss_step=1.220, training_loss_epoch=1.490, val_loss_step=1.050]\n",
      "Validating:  38%|███▊      | 36/94 [00:01<00:01, 50.77it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 522/563 [00:15<00:01, 34.06it/s, loss=1.1, v_num=70, val_loss_epoch=1.410, training_loss_step=1.220, training_loss_epoch=1.490, val_loss_step=1.050]\n",
      "Validating:  60%|█████▉    | 56/94 [00:01<00:00, 62.64it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 540/563 [00:15<00:00, 34.63it/s, loss=1.1, v_num=70, val_loss_epoch=1.410, training_loss_step=1.220, training_loss_epoch=1.490, val_loss_step=1.050]\n",
      "Epoch 5:  99%|█████████▉| 558/563 [00:15<00:00, 35.52it/s, loss=1.1, v_num=70, val_loss_epoch=1.410, training_loss_step=1.220, training_loss_epoch=1.490, val_loss_step=1.050]\n",
      "Epoch 5: 100%|██████████| 563/563 [00:16<00:00, 35.09it/s, loss=1.1, v_num=70, val_loss_epoch=1.170, training_loss_step=1.400, training_loss_epoch=1.160, val_loss_step=0.768]\n",
      "Epoch 6:  83%|████████▎ | 469/563 [00:13<00:02, 34.93it/s, loss=0.814, v_num=70, val_loss_epoch=1.170, training_loss_step=0.776, training_loss_epoch=1.160, val_loss_step=0.768]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:21,  1.14it/s]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 486/563 [00:14<00:02, 33.41it/s, loss=0.814, v_num=70, val_loss_epoch=1.170, training_loss_step=0.776, training_loss_epoch=1.160, val_loss_step=0.768]\n",
      "Validating:  24%|██▍       | 23/94 [00:01<00:02, 32.39it/s]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 504/563 [00:14<00:01, 34.28it/s, loss=0.814, v_num=70, val_loss_epoch=1.170, training_loss_step=0.776, training_loss_epoch=1.160, val_loss_step=0.768]\n",
      "Epoch 6:  93%|█████████▎| 522/563 [00:14<00:01, 34.90it/s, loss=0.814, v_num=70, val_loss_epoch=1.170, training_loss_step=0.776, training_loss_epoch=1.160, val_loss_step=0.768]\n",
      "Validating:  56%|█████▋    | 53/94 [00:01<00:00, 58.01it/s]\u001b[A\n",
      "Validating:  65%|██████▍   | 61/94 [00:01<00:00, 60.37it/s]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 540/563 [00:15<00:00, 35.51it/s, loss=0.814, v_num=70, val_loss_epoch=1.170, training_loss_step=0.776, training_loss_epoch=1.160, val_loss_step=0.768]\n",
      "Epoch 6: 100%|██████████| 563/563 [00:15<00:00, 35.91it/s, loss=0.814, v_num=70, val_loss_epoch=1.010, training_loss_step=0.669, training_loss_epoch=0.942, val_loss_step=0.600]\n",
      "Epoch 7:  83%|████████▎ | 469/563 [00:13<00:02, 34.53it/s, loss=0.71, v_num=70, val_loss_epoch=1.010, training_loss_step=0.798, training_loss_epoch=0.942, val_loss_step=0.600] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:22,  1.12it/s]\u001b[A\n",
      "Validating:   9%|▊         | 8/94 [00:00<00:08, 10.56it/s]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 486/563 [00:14<00:02, 32.88it/s, loss=0.71, v_num=70, val_loss_epoch=1.010, training_loss_step=0.798, training_loss_epoch=0.942, val_loss_step=0.600]\n",
      "Validating:  26%|██▌       | 24/94 [00:01<00:02, 31.75it/s]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 504/563 [00:15<00:01, 33.59it/s, loss=0.71, v_num=70, val_loss_epoch=1.010, training_loss_step=0.798, training_loss_epoch=0.942, val_loss_step=0.600]\n",
      "Epoch 7:  93%|█████████▎| 522/563 [00:15<00:01, 34.48it/s, loss=0.71, v_num=70, val_loss_epoch=1.010, training_loss_step=0.798, training_loss_epoch=0.942, val_loss_step=0.600]\n",
      "Validating:  61%|██████    | 57/94 [00:01<00:00, 72.68it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 540/563 [00:15<00:00, 35.12it/s, loss=0.71, v_num=70, val_loss_epoch=1.010, training_loss_step=0.798, training_loss_epoch=0.942, val_loss_step=0.600]\n",
      "Validating:  81%|████████  | 76/94 [00:01<00:00, 74.61it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 558/563 [00:15<00:00, 35.73it/s, loss=0.71, v_num=70, val_loss_epoch=1.010, training_loss_step=0.798, training_loss_epoch=0.942, val_loss_step=0.600]\n",
      "Epoch 7: 100%|██████████| 563/563 [00:16<00:00, 35.12it/s, loss=0.71, v_num=70, val_loss_epoch=0.863, training_loss_step=0.822, training_loss_epoch=0.783, val_loss_step=0.447]\n",
      "Epoch 8:  83%|████████▎ | 469/563 [00:13<00:02, 34.78it/s, loss=0.7, v_num=70, val_loss_epoch=0.863, training_loss_step=0.567, training_loss_epoch=0.783, val_loss_step=0.447]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:21,  1.14it/s]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 486/563 [00:14<00:02, 33.21it/s, loss=0.7, v_num=70, val_loss_epoch=0.863, training_loss_step=0.567, training_loss_epoch=0.783, val_loss_step=0.447]\n",
      "Validating:  20%|██        | 19/94 [00:01<00:02, 25.10it/s]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 504/563 [00:14<00:01, 33.94it/s, loss=0.7, v_num=70, val_loss_epoch=0.863, training_loss_step=0.567, training_loss_epoch=0.783, val_loss_step=0.447]\n",
      "Validating:  39%|███▉      | 37/94 [00:01<00:01, 45.70it/s]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 522/563 [00:15<00:01, 34.60it/s, loss=0.7, v_num=70, val_loss_epoch=0.863, training_loss_step=0.567, training_loss_epoch=0.783, val_loss_step=0.447]\n",
      "Validating:  57%|█████▋    | 54/94 [00:01<00:00, 59.18it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 540/563 [00:15<00:00, 35.26it/s, loss=0.7, v_num=70, val_loss_epoch=0.863, training_loss_step=0.567, training_loss_epoch=0.783, val_loss_step=0.447]\n",
      "Validating:  77%|███████▋  | 72/94 [00:01<00:00, 67.63it/s]\u001b[A\n",
      "Epoch 8: 100%|██████████| 563/563 [00:15<00:00, 35.58it/s, loss=0.7, v_num=70, val_loss_epoch=0.793, training_loss_step=1.270, training_loss_epoch=0.668, val_loss_step=0.341]\n",
      "Epoch 9:  83%|████████▎ | 469/563 [00:10<00:02, 42.93it/s, loss=0.527, v_num=70, val_loss_epoch=0.793, training_loss_step=0.512, training_loss_epoch=0.668, val_loss_step=0.341]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:15,  1.23it/s]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 486/563 [00:11<00:01, 40.59it/s, loss=0.527, v_num=70, val_loss_epoch=0.793, training_loss_step=0.512, training_loss_epoch=0.668, val_loss_step=0.341]\n",
      "Epoch 9:  90%|████████▉ | 504/563 [00:12<00:01, 41.66it/s, loss=0.527, v_num=70, val_loss_epoch=0.793, training_loss_step=0.512, training_loss_epoch=0.668, val_loss_step=0.341]\n",
      "Epoch 9:  93%|█████████▎| 522/563 [00:12<00:00, 42.68it/s, loss=0.527, v_num=70, val_loss_epoch=0.793, training_loss_step=0.512, training_loss_epoch=0.668, val_loss_step=0.341]\n",
      "Validating:  56%|█████▋    | 53/94 [00:01<00:00, 76.47it/s]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 540/563 [00:12<00:00, 43.67it/s, loss=0.527, v_num=70, val_loss_epoch=0.793, training_loss_step=0.512, training_loss_epoch=0.668, val_loss_step=0.341]\n",
      "Epoch 9: 100%|██████████| 563/563 [00:12<00:00, 43.97it/s, loss=0.527, v_num=70, val_loss_epoch=0.712, training_loss_step=0.587, training_loss_epoch=0.582, val_loss_step=0.343]\n",
      "Epoch 10:  83%|████████▎ | 469/563 [00:13<00:02, 35.35it/s, loss=0.514, v_num=70, val_loss_epoch=0.712, training_loss_step=0.547, training_loss_epoch=0.582, val_loss_step=0.343]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:20,  1.15it/s]\u001b[A\n",
      "Epoch 10:  86%|████████▋ | 486/563 [00:14<00:02, 33.76it/s, loss=0.514, v_num=70, val_loss_epoch=0.712, training_loss_step=0.547, training_loss_epoch=0.582, val_loss_step=0.343]\n",
      "Validating:  21%|██▏       | 20/94 [00:01<00:02, 26.97it/s]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 504/563 [00:14<00:01, 34.41it/s, loss=0.514, v_num=70, val_loss_epoch=0.712, training_loss_step=0.547, training_loss_epoch=0.582, val_loss_step=0.343]\n",
      "Validating:  38%|███▊      | 36/94 [00:01<00:01, 44.31it/s]\u001b[A\n",
      "Validating:  47%|████▋     | 44/94 [00:01<00:00, 50.99it/s]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 522/563 [00:14<00:01, 35.05it/s, loss=0.514, v_num=70, val_loss_epoch=0.712, training_loss_step=0.547, training_loss_epoch=0.582, val_loss_step=0.343]\n",
      "Epoch 10:  96%|█████████▌| 540/563 [00:15<00:00, 35.88it/s, loss=0.514, v_num=70, val_loss_epoch=0.712, training_loss_step=0.547, training_loss_epoch=0.582, val_loss_step=0.343]\n",
      "Validating:  81%|████████  | 76/94 [00:01<00:00, 75.64it/s]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 558/563 [00:15<00:00, 36.51it/s, loss=0.514, v_num=70, val_loss_epoch=0.712, training_loss_step=0.547, training_loss_epoch=0.582, val_loss_step=0.343]\n",
      "Epoch 10: 100%|██████████| 563/563 [00:15<00:00, 35.87it/s, loss=0.514, v_num=70, val_loss_epoch=0.687, training_loss_step=0.510, training_loss_epoch=0.505, val_loss_step=0.283]\n",
      "Epoch 11:  83%|████████▎ | 469/563 [00:13<00:02, 33.59it/s, loss=0.424, v_num=70, val_loss_epoch=0.687, training_loss_step=0.661, training_loss_epoch=0.505, val_loss_step=0.283]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:22,  1.13it/s]\u001b[A\n",
      "Validating:   7%|▋         | 7/94 [00:00<00:09,  9.24it/s]\u001b[A\n",
      "Epoch 11:  86%|████████▋ | 486/563 [00:15<00:02, 32.03it/s, loss=0.424, v_num=70, val_loss_epoch=0.687, training_loss_step=0.661, training_loss_epoch=0.505, val_loss_step=0.283]\n",
      "Validating:  24%|██▍       | 23/94 [00:01<00:02, 31.33it/s]\u001b[A\n",
      "Epoch 11:  90%|████████▉ | 504/563 [00:15<00:01, 32.69it/s, loss=0.424, v_num=70, val_loss_epoch=0.687, training_loss_step=0.661, training_loss_epoch=0.505, val_loss_step=0.283]\n",
      "Validating:  41%|████▏     | 39/94 [00:01<00:01, 49.32it/s]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 522/563 [00:15<00:01, 33.45it/s, loss=0.424, v_num=70, val_loss_epoch=0.687, training_loss_step=0.661, training_loss_epoch=0.505, val_loss_step=0.283]\n",
      "Validating:  64%|██████▍   | 60/94 [00:01<00:00, 66.66it/s]\u001b[A\n",
      "Epoch 11:  96%|█████████▌| 540/563 [00:15<00:00, 34.07it/s, loss=0.424, v_num=70, val_loss_epoch=0.687, training_loss_step=0.661, training_loss_epoch=0.505, val_loss_step=0.283]\n",
      "Validating:  81%|████████  | 76/94 [00:01<00:00, 69.65it/s]\u001b[A\n",
      "Epoch 11: 100%|██████████| 563/563 [00:16<00:00, 34.17it/s, loss=0.424, v_num=70, val_loss_epoch=0.624, training_loss_step=0.198, training_loss_epoch=0.448, val_loss_step=0.318]\n",
      "Epoch 12:  83%|████████▎ | 469/563 [00:13<00:02, 34.85it/s, loss=0.441, v_num=70, val_loss_epoch=0.624, training_loss_step=0.416, training_loss_epoch=0.448, val_loss_step=0.318]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:19,  1.17it/s]\u001b[A\n",
      "Epoch 12:  86%|████████▋ | 486/563 [00:14<00:02, 33.38it/s, loss=0.441, v_num=70, val_loss_epoch=0.624, training_loss_step=0.416, training_loss_epoch=0.448, val_loss_step=0.318]\n",
      "Validating:  21%|██▏       | 20/94 [00:01<00:02, 26.97it/s]\u001b[A\n",
      "Epoch 12:  90%|████████▉ | 504/563 [00:14<00:01, 34.02it/s, loss=0.441, v_num=70, val_loss_epoch=0.624, training_loss_step=0.416, training_loss_epoch=0.448, val_loss_step=0.318]\n",
      "Validating:  38%|███▊      | 36/94 [00:01<00:01, 43.28it/s]\u001b[A\n",
      "Validating:  46%|████▌     | 43/94 [00:01<00:01, 45.92it/s]\u001b[A\n",
      "Epoch 12:  93%|█████████▎| 522/563 [00:15<00:01, 34.57it/s, loss=0.441, v_num=70, val_loss_epoch=0.624, training_loss_step=0.416, training_loss_epoch=0.448, val_loss_step=0.318]\n",
      "Validating:  64%|██████▍   | 60/94 [00:01<00:00, 60.66it/s]\u001b[A\n",
      "Epoch 12:  96%|█████████▌| 540/563 [00:15<00:00, 35.16it/s, loss=0.441, v_num=70, val_loss_epoch=0.624, training_loss_step=0.416, training_loss_epoch=0.448, val_loss_step=0.318]\n",
      "Validating:  82%|████████▏ | 77/94 [00:01<00:00, 66.26it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 558/563 [00:15<00:00, 35.80it/s, loss=0.441, v_num=70, val_loss_epoch=0.624, training_loss_step=0.416, training_loss_epoch=0.448, val_loss_step=0.318]\n",
      "Epoch 12: 100%|██████████| 563/563 [00:16<00:00, 35.10it/s, loss=0.441, v_num=70, val_loss_epoch=0.594, training_loss_step=0.451, training_loss_epoch=0.395, val_loss_step=0.273]\n",
      "Epoch 13:  83%|████████▎ | 469/563 [00:14<00:02, 32.62it/s, loss=0.337, v_num=70, val_loss_epoch=0.594, training_loss_step=0.345, training_loss_epoch=0.395, val_loss_step=0.273]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:24,  1.10it/s]\u001b[A\n",
      "Validating:   6%|▋         | 6/94 [00:01<00:11,  7.67it/s]\u001b[A\n",
      "Epoch 13:  86%|████████▋ | 486/563 [00:15<00:02, 31.13it/s, loss=0.337, v_num=70, val_loss_epoch=0.594, training_loss_step=0.345, training_loss_epoch=0.395, val_loss_step=0.273]\n",
      "Epoch 13:  90%|████████▉ | 504/563 [00:15<00:01, 31.97it/s, loss=0.337, v_num=70, val_loss_epoch=0.594, training_loss_step=0.345, training_loss_epoch=0.395, val_loss_step=0.273]\n",
      "Validating:  39%|███▉      | 37/94 [00:01<00:01, 52.37it/s]\u001b[A\n",
      "Epoch 13:  93%|█████████▎| 522/563 [00:16<00:01, 32.62it/s, loss=0.337, v_num=70, val_loss_epoch=0.594, training_loss_step=0.345, training_loss_epoch=0.395, val_loss_step=0.273]\n",
      "Validating:  59%|█████▊    | 55/94 [00:01<00:00, 61.91it/s]\u001b[A\n",
      "Epoch 13:  96%|█████████▌| 540/563 [00:16<00:00, 33.20it/s, loss=0.337, v_num=70, val_loss_epoch=0.594, training_loss_step=0.345, training_loss_epoch=0.395, val_loss_step=0.273]\n",
      "Validating:  76%|███████▌  | 71/94 [00:01<00:00, 65.14it/s]\u001b[A\n",
      "Epoch 13: 100%|██████████| 563/563 [00:16<00:00, 33.58it/s, loss=0.337, v_num=70, val_loss_epoch=0.571, training_loss_step=0.326, training_loss_epoch=0.353, val_loss_step=0.187]\n",
      "Epoch 14:  83%|████████▎ | 469/563 [00:14<00:02, 33.02it/s, loss=0.332, v_num=70, val_loss_epoch=0.571, training_loss_step=0.213, training_loss_epoch=0.353, val_loss_step=0.187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:23,  1.11it/s]\u001b[A\n",
      "Epoch 14:  86%|████████▋ | 486/563 [00:15<00:02, 31.72it/s, loss=0.332, v_num=70, val_loss_epoch=0.571, training_loss_step=0.213, training_loss_epoch=0.353, val_loss_step=0.187]\n",
      "Validating:  27%|██▋       | 25/94 [00:01<00:02, 34.16it/s]\u001b[A\n",
      "Epoch 14:  90%|████████▉ | 504/563 [00:15<00:01, 32.44it/s, loss=0.332, v_num=70, val_loss_epoch=0.571, training_loss_step=0.213, training_loss_epoch=0.353, val_loss_step=0.187]\n",
      "Validating:  46%|████▌     | 43/94 [00:01<00:01, 48.97it/s]\u001b[A\n",
      "Epoch 14:  93%|█████████▎| 522/563 [00:15<00:01, 33.05it/s, loss=0.332, v_num=70, val_loss_epoch=0.571, training_loss_step=0.213, training_loss_epoch=0.353, val_loss_step=0.187]\n",
      "Epoch 14:  96%|█████████▌| 540/563 [00:15<00:00, 33.80it/s, loss=0.332, v_num=70, val_loss_epoch=0.571, training_loss_step=0.213, training_loss_epoch=0.353, val_loss_step=0.187]\n",
      "Validating:  77%|███████▋  | 72/94 [00:01<00:00, 73.18it/s]\u001b[A\n",
      "Epoch 14:  99%|█████████▉| 558/563 [00:16<00:00, 34.41it/s, loss=0.332, v_num=70, val_loss_epoch=0.571, training_loss_step=0.213, training_loss_epoch=0.353, val_loss_step=0.187]\n",
      "Epoch 14: 100%|██████████| 563/563 [00:16<00:00, 33.86it/s, loss=0.332, v_num=70, val_loss_epoch=0.537, training_loss_step=0.215, training_loss_epoch=0.321, val_loss_step=0.228]\n",
      "Epoch 15:  83%|████████▎ | 469/563 [00:13<00:02, 34.42it/s, loss=0.288, v_num=70, val_loss_epoch=0.537, training_loss_step=0.164, training_loss_epoch=0.321, val_loss_step=0.228] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:22,  1.13it/s]\u001b[A\n",
      "Validating:   6%|▋         | 6/94 [00:00<00:11,  7.88it/s]\u001b[A\n",
      "Epoch 15:  86%|████████▋ | 486/563 [00:14<00:02, 32.77it/s, loss=0.288, v_num=70, val_loss_epoch=0.537, training_loss_step=0.164, training_loss_epoch=0.321, val_loss_step=0.228]\n",
      "Epoch 15:  90%|████████▉ | 504/563 [00:15<00:01, 33.58it/s, loss=0.288, v_num=70, val_loss_epoch=0.537, training_loss_step=0.164, training_loss_epoch=0.321, val_loss_step=0.228]\n",
      "Validating:  38%|███▊      | 36/94 [00:01<00:01, 49.19it/s]\u001b[A\n",
      "Validating:  47%|████▋     | 44/94 [00:01<00:00, 55.84it/s]\u001b[A\n",
      "Epoch 15:  93%|█████████▎| 522/563 [00:15<00:01, 34.22it/s, loss=0.288, v_num=70, val_loss_epoch=0.537, training_loss_step=0.164, training_loss_epoch=0.321, val_loss_step=0.228]\n",
      "Validating:  64%|██████▍   | 60/94 [00:01<00:00, 62.10it/s]\u001b[A\n",
      "Epoch 15:  96%|█████████▌| 540/563 [00:15<00:00, 34.87it/s, loss=0.288, v_num=70, val_loss_epoch=0.537, training_loss_step=0.164, training_loss_epoch=0.321, val_loss_step=0.228]\n",
      "Epoch 15:  99%|█████████▉| 558/563 [00:15<00:00, 35.68it/s, loss=0.288, v_num=70, val_loss_epoch=0.537, training_loss_step=0.164, training_loss_epoch=0.321, val_loss_step=0.228]\n",
      "Epoch 15: 100%|██████████| 563/563 [00:16<00:00, 35.18it/s, loss=0.288, v_num=70, val_loss_epoch=0.533, training_loss_step=0.278, training_loss_epoch=0.288, val_loss_step=0.144]\n",
      "Epoch 16:  83%|████████▎ | 469/563 [00:13<00:02, 33.62it/s, loss=0.216, v_num=70, val_loss_epoch=0.533, training_loss_step=0.235, training_loss_epoch=0.288, val_loss_step=0.144] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:21,  1.14it/s]\u001b[A\n",
      "Epoch 16:  86%|████████▋ | 486/563 [00:15<00:02, 32.14it/s, loss=0.216, v_num=70, val_loss_epoch=0.533, training_loss_step=0.235, training_loss_epoch=0.288, val_loss_step=0.144]\n",
      "Validating:  18%|█▊        | 17/94 [00:01<00:03, 22.89it/s]\u001b[A\n",
      "Epoch 16:  90%|████████▉ | 504/563 [00:15<00:01, 32.86it/s, loss=0.216, v_num=70, val_loss_epoch=0.533, training_loss_step=0.235, training_loss_epoch=0.288, val_loss_step=0.144]\n",
      "Validating:  37%|███▋      | 35/94 [00:01<00:01, 46.82it/s]\u001b[A\n",
      "Epoch 16:  93%|█████████▎| 522/563 [00:15<00:01, 33.56it/s, loss=0.216, v_num=70, val_loss_epoch=0.533, training_loss_step=0.235, training_loss_epoch=0.288, val_loss_step=0.144]\n",
      "Validating:  57%|█████▋    | 54/94 [00:01<00:00, 61.31it/s]\u001b[A\n",
      "Validating:  66%|██████▌   | 62/94 [00:01<00:00, 65.30it/s]\u001b[A\n",
      "Epoch 16:  96%|█████████▌| 540/563 [00:15<00:00, 34.17it/s, loss=0.216, v_num=70, val_loss_epoch=0.533, training_loss_step=0.235, training_loss_epoch=0.288, val_loss_step=0.144]\n",
      "Epoch 16: 100%|██████████| 563/563 [00:16<00:00, 34.43it/s, loss=0.216, v_num=70, val_loss_epoch=0.508, training_loss_step=0.132, training_loss_epoch=0.260, val_loss_step=0.155]\n",
      "Epoch 17:  83%|████████▎ | 469/563 [00:13<00:02, 34.68it/s, loss=0.232, v_num=70, val_loss_epoch=0.508, training_loss_step=0.146, training_loss_epoch=0.260, val_loss_step=0.155] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:21,  1.13it/s]\u001b[A\n",
      "Epoch 17:  86%|████████▋ | 486/563 [00:14<00:02, 33.17it/s, loss=0.232, v_num=70, val_loss_epoch=0.508, training_loss_step=0.146, training_loss_epoch=0.260, val_loss_step=0.155]\n",
      "Validating:  22%|██▏       | 21/94 [00:01<00:02, 27.17it/s]\u001b[A\n",
      "Epoch 17:  90%|████████▉ | 504/563 [00:14<00:01, 33.85it/s, loss=0.232, v_num=70, val_loss_epoch=0.508, training_loss_step=0.146, training_loss_epoch=0.260, val_loss_step=0.155]\n",
      "Validating:  39%|███▉      | 37/94 [00:01<00:01, 45.18it/s]\u001b[A\n",
      "Epoch 17:  93%|█████████▎| 522/563 [00:15<00:01, 34.52it/s, loss=0.232, v_num=70, val_loss_epoch=0.508, training_loss_step=0.146, training_loss_epoch=0.260, val_loss_step=0.155]\n",
      "Validating:  60%|█████▉    | 56/94 [00:01<00:00, 65.01it/s]\u001b[A\n",
      "Epoch 17:  96%|█████████▌| 540/563 [00:15<00:00, 35.23it/s, loss=0.232, v_num=70, val_loss_epoch=0.508, training_loss_step=0.146, training_loss_epoch=0.260, val_loss_step=0.155]\n",
      "Validating:  79%|███████▊  | 74/94 [00:01<00:00, 72.13it/s]\u001b[A\n",
      "Epoch 17:  99%|█████████▉| 558/563 [00:15<00:00, 35.85it/s, loss=0.232, v_num=70, val_loss_epoch=0.508, training_loss_step=0.146, training_loss_epoch=0.260, val_loss_step=0.155]\n",
      "Epoch 17: 100%|██████████| 563/563 [00:15<00:00, 35.29it/s, loss=0.232, v_num=70, val_loss_epoch=0.485, training_loss_step=0.109, training_loss_epoch=0.240, val_loss_step=0.121]\n",
      "Epoch 18:  83%|████████▎ | 469/563 [00:13<00:02, 33.53it/s, loss=0.234, v_num=70, val_loss_epoch=0.485, training_loss_step=0.520, training_loss_epoch=0.240, val_loss_step=0.121] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:01<01:39,  1.07s/it]\u001b[A\n",
      "Epoch 18:  86%|████████▋ | 486/563 [00:15<00:02, 31.67it/s, loss=0.234, v_num=70, val_loss_epoch=0.485, training_loss_step=0.520, training_loss_epoch=0.240, val_loss_step=0.121]\n",
      "Validating:  18%|█▊        | 17/94 [00:01<00:03, 19.87it/s]\u001b[A\n",
      "Epoch 18:  90%|████████▉ | 504/563 [00:15<00:01, 32.37it/s, loss=0.234, v_num=70, val_loss_epoch=0.485, training_loss_step=0.520, training_loss_epoch=0.240, val_loss_step=0.121]\n",
      "Validating:  37%|███▋      | 35/94 [00:01<00:01, 42.36it/s]\u001b[A\n",
      "Epoch 18:  93%|█████████▎| 522/563 [00:15<00:01, 33.09it/s, loss=0.234, v_num=70, val_loss_epoch=0.485, training_loss_step=0.520, training_loss_epoch=0.240, val_loss_step=0.121]\n",
      "Validating:  59%|█████▊    | 55/94 [00:01<00:00, 60.01it/s]\u001b[A\n",
      "Epoch 18:  96%|█████████▌| 540/563 [00:16<00:00, 33.70it/s, loss=0.234, v_num=70, val_loss_epoch=0.485, training_loss_step=0.520, training_loss_epoch=0.240, val_loss_step=0.121]\n",
      "Validating:  76%|███████▌  | 71/94 [00:01<00:00, 65.44it/s]\u001b[A\n",
      "Epoch 18: 100%|██████████| 563/563 [00:16<00:00, 34.03it/s, loss=0.234, v_num=70, val_loss_epoch=0.470, training_loss_step=0.158, training_loss_epoch=0.219, val_loss_step=0.156]\n",
      "Epoch 19:  83%|████████▎ | 469/563 [00:13<00:02, 34.90it/s, loss=0.204, v_num=70, val_loss_epoch=0.470, training_loss_step=0.178, training_loss_epoch=0.219, val_loss_step=0.156] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:21,  1.14it/s]\u001b[A\n",
      "Epoch 19:  86%|████████▋ | 486/563 [00:14<00:02, 33.39it/s, loss=0.204, v_num=70, val_loss_epoch=0.470, training_loss_step=0.178, training_loss_epoch=0.219, val_loss_step=0.156]\n",
      "Validating:  21%|██▏       | 20/94 [00:01<00:02, 27.65it/s]\u001b[A\n",
      "Epoch 19:  90%|████████▉ | 504/563 [00:14<00:01, 34.06it/s, loss=0.204, v_num=70, val_loss_epoch=0.470, training_loss_step=0.178, training_loss_epoch=0.219, val_loss_step=0.156]\n",
      "Validating:  38%|███▊      | 36/94 [00:01<00:01, 45.63it/s]\u001b[A\n",
      "Validating:  47%|████▋     | 44/94 [00:01<00:00, 52.81it/s]\u001b[A\n",
      "Epoch 19:  93%|█████████▎| 522/563 [00:15<00:01, 34.71it/s, loss=0.204, v_num=70, val_loss_epoch=0.470, training_loss_step=0.178, training_loss_epoch=0.219, val_loss_step=0.156]\n",
      "Epoch 19:  96%|█████████▌| 540/563 [00:15<00:00, 35.54it/s, loss=0.204, v_num=70, val_loss_epoch=0.470, training_loss_step=0.178, training_loss_epoch=0.219, val_loss_step=0.156]\n",
      "Validating:  80%|███████▉  | 75/94 [00:01<00:00, 78.76it/s]\u001b[A\n",
      "Epoch 19:  99%|█████████▉| 558/563 [00:15<00:00, 36.17it/s, loss=0.204, v_num=70, val_loss_epoch=0.470, training_loss_step=0.178, training_loss_epoch=0.219, val_loss_step=0.156]\n",
      "Epoch 19: 100%|██████████| 563/563 [00:15<00:00, 35.62it/s, loss=0.204, v_num=70, val_loss_epoch=0.464, training_loss_step=0.128, training_loss_epoch=0.197, val_loss_step=0.140]\n",
      "Epoch 20:  83%|████████▎ | 469/563 [00:13<00:02, 34.53it/s, loss=0.136, v_num=70, val_loss_epoch=0.464, training_loss_step=0.0954, training_loss_epoch=0.197, val_loss_step=0.140]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:00<01:21,  1.14it/s]\u001b[A\n",
      "Validating:   9%|▊         | 8/94 [00:00<00:07, 10.76it/s]\u001b[A\n",
      "Epoch 20:  86%|████████▋ | 486/563 [00:14<00:02, 32.91it/s, loss=0.136, v_num=70, val_loss_epoch=0.464, training_loss_step=0.0954, training_loss_epoch=0.197, val_loss_step=0.140]\n",
      "Epoch 20:  90%|████████▉ | 504/563 [00:14<00:01, 33.67it/s, loss=0.136, v_num=70, val_loss_epoch=0.464, training_loss_step=0.0954, training_loss_epoch=0.197, val_loss_step=0.140]\n",
      "Validating:  37%|███▋      | 35/94 [00:01<00:01, 48.11it/s]\u001b[A\n",
      "Epoch 20:  93%|█████████▎| 522/563 [00:15<00:01, 34.53it/s, loss=0.136, v_num=70, val_loss_epoch=0.464, training_loss_step=0.0954, training_loss_epoch=0.197, val_loss_step=0.140]\n",
      "Epoch 20:  96%|█████████▌| 540/563 [00:15<00:00, 35.17it/s, loss=0.136, v_num=70, val_loss_epoch=0.464, training_loss_step=0.0954, training_loss_epoch=0.197, val_loss_step=0.140]\n",
      "Validating:  76%|███████▌  | 71/94 [00:01<00:00, 72.69it/s]\u001b[A\n",
      "Epoch 20:  99%|█████████▉| 558/563 [00:15<00:00, 35.78it/s, loss=0.136, v_num=70, val_loss_epoch=0.464, training_loss_step=0.0954, training_loss_epoch=0.197, val_loss_step=0.140]\n",
      "Epoch 20: 100%|██████████| 563/563 [00:15<00:00, 35.28it/s, loss=0.136, v_num=70, val_loss_epoch=0.441, training_loss_step=0.120, training_loss_epoch=0.182, val_loss_step=0.165] \n",
      "Epoch 20: 100%|██████████| 563/563 [00:15<00:00, 35.25it/s, loss=0.136, v_num=70, val_loss_epoch=0.441, training_loss_step=0.120, training_loss_epoch=0.182, val_loss_step=0.165]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=intent_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "southwest-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IntentClassifier.load_from_checkpoint('./lightning_logs/version_70/checkpoints/epoch=17-step=8441.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "liked-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 141/141 [00:02<00:00, 54.53it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.test(model, datamodule=intent_dm)\n",
    "test_preds = model.test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "framed-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/50517921\n",
    "TAG_MAP = [\n",
    "    \".\",        \n",
    "    \",\",        \n",
    "    \"-LRB-\",    \n",
    "    \"-RRB-\",    \n",
    "    \"``\",       \n",
    "    \"\\\"\\\"\",     \n",
    "    \"''\",       \n",
    "    \",\",        \n",
    "    \"$\",        \n",
    "    \"#\",        \n",
    "    \"AFX\",      \n",
    "    \"CC\",       \n",
    "    \"CD\",       \n",
    "    \"DT\",       \n",
    "    \"EX\",       \n",
    "    \"FW\",       \n",
    "    \"HYPH\",     \n",
    "    \"IN\",       \n",
    "    \"JJ\",       \n",
    "    \"JJR\",      \n",
    "    \"JJS\",      \n",
    "    \"LS\",       \n",
    "    \"MD\",       \n",
    "    \"NIL\",      \n",
    "    \"NN\",       \n",
    "    \"NNP\",      \n",
    "    \"NNPS\",     \n",
    "    \"NNS\",   \n",
    "    \"PDT\",   \n",
    "    \"POS\",   \n",
    "    \"PRP\",   \n",
    "    \"PRP$\",  \n",
    "    \"RB\",    \n",
    "    \"RBR\",   \n",
    "    \"RBS\",   \n",
    "    \"RP\",    \n",
    "    \"SP\",    \n",
    "    \"SYM\",   \n",
    "    \"TO\",    \n",
    "    \"UH\",    \n",
    "    \"VB\",    \n",
    "    \"VBD\",  \n",
    "    \"VBG\",  \n",
    "    \"VBN\",  \n",
    "    \"VBP\",  \n",
    "    \"VBZ\",  \n",
    "    \"WDT\",  \n",
    "    \"WP\",   \n",
    "    \"WP$\",  \n",
    "    \"WRB\",  \n",
    "    \"ADD\",  \n",
    "    \"NFP\",   \n",
    "    \"GW\",    \n",
    "    \"XX\",    \n",
    "    \"BES\",   \n",
    "    \"HVS\",   \n",
    "    \"_SP\",   \n",
    "]\n",
    "others = list(spacy.load('en_core_web_md').pipeline[1][1].labels)\n",
    "combined = list(set(TAG_MAP + others))\n",
    "with open('../data/pos_to_idx.json', 'w') as f:\n",
    "    tags = {t: idx for idx, t in enumerate(combined)}\n",
    "    json.dump(tags, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-accent",
   "metadata": {},
   "source": [
    "## Dataset Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "about-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentPosDataset(Dataset):\n",
    "    def __init__(self, data_path: str, train: bool, intent_mapping: Dict[str, int], pos_map_path: str = \"../data/pos_to_idx.json\", glove: Optional[Dict[str, np.array]] = None, glove_path: str = \"../../data/glove.840B.300d.pkl.gz\", unk_token_strategy='average'):\n",
    "        with open(data_path) as f: \n",
    "            self.data = json.load(f)\n",
    "        self.intent_to_idx = intent_mapping\n",
    "        self.train = train\n",
    "        self.glove = glove\n",
    "        self.nlp = spacy.load('en_core_web_md')\n",
    "        with open(pos_map_path) as f:\n",
    "            self.tag_to_idx = json.load(f)\n",
    "        self.unk_token_strategy = unk_token_strategy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        _id = sample['id']\n",
    "        text = sample['text']\n",
    "        doc = self.nlp(text)\n",
    "        toks = [d.text for d in doc]\n",
    "        text = self.convert_to_vectors(toks, _id)\n",
    "        length = len(text)\n",
    "        out = {\n",
    "            'id': _id,\n",
    "            'text': text,\n",
    "            'length': length\n",
    "        }\n",
    "        if self.train:\n",
    "            intent = sample['intent']\n",
    "            intent = self.intent_to_idx[intent]\n",
    "            tags = [d.tag_ for d in doc]\n",
    "            tags = [self.tag_to_idx[t] for t in tags]\n",
    "            \n",
    "            out['tags'] = tags\n",
    "            out['intent'] = intent\n",
    "        return out\n",
    "        \n",
    "    def convert_to_vectors(self, text, _id):\n",
    "        vectors = []\n",
    "        missing_idx = []\n",
    "        \n",
    "        for idx, tok in enumerate(text):\n",
    "            try:\n",
    "                vector = torch.from_numpy(self.glove[tok]).float()\n",
    "            except KeyError:\n",
    "#                 avg = torch.mean(torch.stack(vectors), axis=0)\n",
    "                missing_idx.append(idx)\n",
    "                vectors.append(torch.zeros(300))\n",
    "#                 vectors.append(avg)\n",
    "                continue\n",
    "            else:\n",
    "                vectors.append(vector)\n",
    "                \n",
    "        if len(vectors) == len(missing_idx):\n",
    "            return torch.stack(vectors)\n",
    "        \n",
    "        if self.unk_token_strategy == 'ignore':\n",
    "            return torch.stack(vectors)\n",
    "        \n",
    "        elif self.unk_token_strategy == 'average':\n",
    "            if missing_idx:\n",
    "                vectors = self._average_tokens(vectors, missing_idx)\n",
    "                \n",
    "        vectors = torch.stack(vectors)\n",
    "        if torch.isnan(vectors).sum() > 0:\n",
    "            print('NaN in embeddings!')\n",
    "            print(_id)\n",
    "            raise Exception\n",
    "                \n",
    "        return vectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def _average_tokens(vectors: list, missing_idxs: list, window: int = 2):\n",
    "        for m in missing_idxs:\n",
    "            avg = vectors[max(m-window, 0): m] + vectors[m + 1: m+1+window]\n",
    "            if not avg:\n",
    "                avg = torch.stack(vectors)\n",
    "            else:\n",
    "                avg = torch.stack(avg)\n",
    "            if avg.sum() == 0:\n",
    "                vectors[m] = torch.zeros(300)\n",
    "                continue\n",
    "            avg = avg[avg.nonzero(as_tuple=True)].view(-1, avg.shape[1])\n",
    "            avg = torch.mean(avg[avg.nonzero(as_tuple=True)].view(-1, avg.shape[1]), axis=0)\n",
    "            vectors[m] = avg\n",
    "        \n",
    "        return vectors\n",
    "            \n",
    "        \n",
    "class IntentPosDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"../ADL21-HW1/data/intent\", intent_mapping: str = \"../data/intents_to_idx.json\", embedding_obj: Optional[Dict[str, np.array]] = None, embedding_dir: str = \"../../data/glove.840B.300d.gz\", batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.batch_size = batch_size\n",
    "        with open(intent_mapping) as f:\n",
    "            self.intent_to_idx = json.load(f)\n",
    "        if embedding_obj:\n",
    "            self.emb = embedding_obj\n",
    "        else:\n",
    "            self.emb = self._load_glove(embedding_dir)\n",
    "        \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.intent_train = IntentPosDataset(\n",
    "                data_path=self.data_dir.joinpath('train.json'), \n",
    "                train=True,\n",
    "                intent_mapping=self.intent_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "            self.intent_val = IntentPosDataset(\n",
    "                data_path=self.data_dir.joinpath('eval.json'), \n",
    "                train=True,\n",
    "                intent_mapping=self.intent_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "            self.tag_to_idx = self.intent_train.tag_to_idx\n",
    "        elif stage == \"test\" or stage is None:\n",
    "            self.intent_test = IntentPosDataset(\n",
    "                data_path=self.data_dir.joinpath('test.json'), \n",
    "                train=False,\n",
    "                intent_mapping=self.intent_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.intent_train, batch_size=self.batch_size, num_workers=8, pin_memory=True, collate_fn=self._collate_fn(False), shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.intent_val, batch_size=self.batch_size, num_workers=8, pin_memory=True, collate_fn=self._collate_fn(False))\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.intent_test, batch_size=self.batch_size, num_workers=8, pin_memory=True, collate_fn=self._collate_fn(True))\n",
    "        \n",
    "    @staticmethod\n",
    "    def _collate_fn(is_test):\n",
    "        def collate_fn(batch):\n",
    "            out = {}\n",
    "            _id = [b['id'] for b in batch]\n",
    "            text = [b['text'] for b in batch]\n",
    "            length = torch.LongTensor([b['length'] for b in batch])\n",
    "            text = pad_sequence(text, batch_first=True)\n",
    "            if not is_test:\n",
    "                intent = torch.LongTensor([b['intent'] for b in batch])\n",
    "                tags = [torch.LongTensor(b['tags']) for b in batch]\n",
    "                tags = pad_sequence(tags, batch_first=True, padding_value=-1)\n",
    "                out['intent'] = intent\n",
    "                out['tags'] = tags\n",
    "\n",
    "            out['id'] = _id\n",
    "            out['text'] = text\n",
    "            out['length'] = length\n",
    "            out['text'] = text\n",
    "            return out\n",
    "        return collate_fn\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_glove(fpath: str) -> Dict[str, torch.FloatTensor]:\n",
    "        logger.info(\"Loading GloVe embeddings...\")\n",
    "        with gzip.open(fpath, 'rb') as f:\n",
    "            emb = pickle.load(f)\n",
    "        logger.info(\"Done!\")\n",
    "        return emb\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-writer",
   "metadata": {},
   "source": [
    "## Model Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "supposed-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentPosClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_intent: int, num_tags: int, hidden_size: int = 512, num_layers: int = 3, bidirectional: bool = True, lr: int = 1e-4, dropout=0, loss_ratio=0.7, multitask=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.multitask = multitask\n",
    "        self.loss_ratio = loss_ratio if multitask else 0.0\n",
    "        self.bidirectional = 2 if bidirectional else 1\n",
    "        self.lr = lr\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=300, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=bidirectional, \n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.hidden_to_labels = nn.Linear(self.hidden_size * self.bidirectional, num_intent)\n",
    "        self.hidden_to_tags = nn.Linear(self.hidden_size * self.bidirectional, num_tags)\n",
    "#         self.task_weight = nn.Linear(num_intent + num_tags, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.save_hyperparameters()\n",
    "        self.test_preds = {\n",
    "            'ids': [],\n",
    "            'logits': []\n",
    "        }\n",
    "        \n",
    "    def forward(self, inpt):\n",
    "        samples = inpt['text']\n",
    "        tags = inpt.get('tags')\n",
    "        lengths = inpt['length'].to('cpu')\n",
    "        batch_size = samples.shape[0]\n",
    "        \n",
    "        samples = pack_padded_sequence(samples, lengths, batch_first=True, enforce_sorted=False)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(samples, hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        hidden = torch.cat([hidden[-1,...], hidden[-2,...]], dim=1)  # concat last hidden states of forwards and backwards\n",
    "        intent_logits = self.hidden_to_labels(hidden)\n",
    "        if tags is not None: \n",
    "            out, out_len = pad_packed_sequence(out, batch_first=True)\n",
    "            out = self.dropout(out)\n",
    "            tag_logits = self.hidden_to_tags(out).permute(0, 2, 1)\n",
    "            return intent_logits, tag_logits\n",
    "            \n",
    "        return intent_logits\n",
    "        \n",
    "    def _shared_step(self, batch):\n",
    "        ids = batch['id']\n",
    "        intent = batch['intent']\n",
    "        tags = batch['tags']\n",
    "        intent_logits, tag_logits = self(batch)\n",
    "        intent_loss = F.cross_entropy(intent_logits, intent)\n",
    "        tag_loss = F.cross_entropy(tag_logits, tags, ignore_index=-1)\n",
    "        return intent_loss, tag_loss\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        intent_loss, tag_loss = self._shared_step(batch)\n",
    "        if self.multitask:\n",
    "            intent_weight = self.loss_ratio\n",
    "            tag_weight = 1.0 - self.loss_ratio\n",
    "            loss = ((intent_loss * intent_weight) + (tag_loss * tag_weight)) \n",
    "        else:\n",
    "            loss = intent_loss\n",
    "        self.log('training_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        intent_loss, tag_loss = self._shared_step(batch)\n",
    "        self.log('val_loss', intent_loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return intent_loss\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids = batch['id']\n",
    "        logits = self(batch)\n",
    "        self.test_preds['ids'].extend(ids)\n",
    "        self.test_preds['logits'].extend(logits)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_logits(logits, idx2int):\n",
    "        preds = torch.stack(logits)\n",
    "        preds = preds.argmax(dim=1).tolist()\n",
    "        preds = [idx2int[p] for p in preds]\n",
    "        return preds\n",
    "            \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.normal(mean=0, std=1, size=(self.bidirectional * self.num_layers, batch_size, self.hidden_size)).to('cuda')\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-equality",
   "metadata": {},
   "source": [
    "## Intent Multitask Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "technological-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 13:30:21,533 - __main__ - INFO - Loading GloVe embeddings...\n",
      "2021-04-10 13:31:02,897 - __main__ - INFO - Done!\n"
     ]
    }
   ],
   "source": [
    "# glove = IntentPosDataModule._load_glove('../../data/glove.840B.300d.pkl.gz')\n",
    "intent_pos_dm = IntentPosDataModule(embedding_obj=glove, batch_size=128)\n",
    "intent_pos_dm.prepare_data()\n",
    "intent_pos_dm.setup('fit')\n",
    "intent_labels = intent_pos_dm.intent_to_idx\n",
    "tag_labels = intent_pos_dm.tag_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "egyptian-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask = True\n",
    "model = IntentPosClassifier(num_intent=len(intent_labels), num_layers=2, num_tags=len(tag_labels), hidden_size=2048, loss_ratio=0.7, dropout=.25, multitask=multitask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "utility-collector",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dclian/adl/hw1/notebooks/intent_mt_lightning_logs\n"
     ]
    }
   ],
   "source": [
    "if multitask:\n",
    "    logging_dir = Path('.').joinpath('intent_mt_lightning_logs')\n",
    "    filename = 'intent_mt-{epoch:02d}-{training_loss:.2f}-{val_loss:.2f}',\n",
    "else:\n",
    "    logging_dir = Path('.').joinpath('intent_lightning_logs')\n",
    "    filename = 'intent-{epoch:02d}-{training_loss:.2f}-{val_loss:.2f}',\n",
    "print(str(logging_dir.resolve()))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    filename='intent_mt-{epoch:02d}-{training_loss:.2f}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    \n",
    "#     auto_lr_find=True,\n",
    "    gpus=[0],\n",
    "#     gradient_clip_val=1,\n",
    "    weights_summary='full',\n",
    "#     precision=16,\n",
    "#     track_grad_norm=2,\n",
    "    default_root_dir=str(logging_dir.resolve()),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss'), checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "boxed-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type    | Params\n",
      "---------------------------------------------\n",
      "0 | rnn              | GRU     | 104 M \n",
      "1 | hidden_to_labels | Linear  | 614 K \n",
      "2 | hidden_to_tags   | Linear  | 233 K \n",
      "3 | dropout          | Dropout | 0     \n",
      "---------------------------------------------\n",
      "105 M     Trainable params\n",
      "0         Non-trainable params\n",
      "105 M     Total params\n",
      "420.988   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|████████▎ | 469/563 [00:26<00:05, 17.43it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 471/563 [00:28<00:05, 16.65it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  84%|████████▍ | 475/563 [00:28<00:05, 16.72it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  85%|████████▌ | 479/563 [00:28<00:05, 16.78it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  86%|████████▌ | 483/563 [00:28<00:04, 16.84it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  87%|████████▋ | 487/563 [00:28<00:04, 16.89it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Validating:  19%|█▉        | 18/94 [00:01<00:04, 17.52it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 491/563 [00:29<00:04, 16.90it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  88%|████████▊ | 495/563 [00:29<00:04, 16.96it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  89%|████████▊ | 499/563 [00:29<00:03, 16.99it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  90%|████████▉ | 504/563 [00:29<00:03, 17.09it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Validating:  38%|███▊      | 36/94 [00:02<00:02, 19.54it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 509/563 [00:29<00:03, 17.05it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  91%|█████████▏| 514/563 [00:30<00:02, 17.12it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  92%|█████████▏| 519/563 [00:30<00:02, 17.19it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Validating:  53%|█████▎    | 50/94 [00:03<00:01, 25.77it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 524/563 [00:30<00:02, 17.23it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Validating:  60%|█████▉    | 56/94 [00:03<00:01, 24.42it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 529/563 [00:30<00:01, 17.27it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  95%|█████████▍| 534/563 [00:30<00:01, 17.35it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Validating:  70%|███████   | 66/94 [00:03<00:01, 27.81it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 539/563 [00:31<00:01, 17.34it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  97%|█████████▋| 544/563 [00:31<00:01, 17.41it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  98%|█████████▊| 549/563 [00:31<00:00, 17.45it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Validating:  85%|████████▌ | 80/94 [00:04<00:00, 25.31it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 554/563 [00:31<00:00, 17.50it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0:  99%|█████████▉| 560/563 [00:31<00:00, 17.63it/s, loss=1.49, v_num=23, val_loss_epoch=5.010, training_loss_step=1.560]\n",
      "Epoch 0: 100%|██████████| 563/563 [00:32<00:00, 17.51it/s, loss=1.49, v_num=23, val_loss_epoch=1.640, training_loss_step=1.610, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Epoch 1:  83%|████████▎ | 469/563 [00:28<00:05, 16.60it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 474/563 [00:29<00:05, 15.93it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:   6%|▋         | 6/94 [00:01<00:16,  5.33it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 480/563 [00:30<00:05, 15.95it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  13%|█▎        | 12/94 [00:01<00:08,  9.65it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 486/563 [00:30<00:04, 16.03it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  19%|█▉        | 18/94 [00:02<00:05, 13.81it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 492/563 [00:30<00:04, 16.09it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  26%|██▌       | 24/94 [00:02<00:03, 19.11it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 498/563 [00:30<00:04, 16.14it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  33%|███▎      | 31/94 [00:02<00:02, 22.12it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 504/563 [00:31<00:03, 16.11it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Epoch 1:  91%|█████████ | 510/563 [00:31<00:03, 16.24it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  45%|████▍     | 42/94 [00:03<00:02, 19.35it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 516/563 [00:31<00:02, 16.25it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  52%|█████▏    | 49/94 [00:03<00:02, 18.82it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 522/563 [00:32<00:02, 16.28it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Epoch 1:  94%|█████████▍| 528/563 [00:32<00:02, 16.35it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  64%|██████▍   | 60/94 [00:04<00:01, 22.82it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 534/563 [00:32<00:01, 16.42it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  70%|███████   | 66/94 [00:04<00:01, 22.58it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 540/563 [00:32<00:01, 16.47it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  77%|███████▋  | 72/94 [00:04<00:00, 24.15it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 546/563 [00:33<00:01, 16.49it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Validating:  83%|████████▎ | 78/94 [00:04<00:00, 22.38it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 552/563 [00:33<00:00, 16.52it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Epoch 1:  99%|█████████▉| 558/563 [00:33<00:00, 16.64it/s, loss=0.674, v_num=23, val_loss_epoch=1.640, training_loss_step=0.842, training_loss_epoch=3.010, val_loss_step=1.090]\n",
      "Epoch 1: 100%|██████████| 563/563 [00:33<00:00, 16.56it/s, loss=0.674, v_num=23, val_loss_epoch=0.815, training_loss_step=0.706, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  83%|████████▎ | 469/563 [00:29<00:05, 16.10it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 472/563 [00:30<00:05, 15.38it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  84%|████████▍ | 475/563 [00:30<00:05, 15.42it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  85%|████████▍ | 478/563 [00:30<00:05, 15.46it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  85%|████████▌ | 481/563 [00:31<00:05, 15.48it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  86%|████████▌ | 485/563 [00:31<00:05, 15.56it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  87%|████████▋ | 489/563 [00:31<00:04, 15.56it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  88%|████████▊ | 493/563 [00:31<00:04, 15.62it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Validating:  26%|██▌       | 24/94 [00:02<00:03, 18.20it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 497/563 [00:31<00:04, 15.63it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  89%|████████▉ | 501/563 [00:31<00:03, 15.69it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  90%|████████▉ | 505/563 [00:32<00:03, 15.73it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  90%|█████████ | 509/563 [00:32<00:03, 15.77it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Validating:  43%|████▎     | 40/94 [00:03<00:02, 22.03it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 513/563 [00:32<00:03, 15.80it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  92%|█████████▏| 517/563 [00:32<00:02, 15.80it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  93%|█████████▎| 521/563 [00:32<00:02, 15.85it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Validating:  55%|█████▌    | 52/94 [00:03<00:01, 22.22it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 525/563 [00:33<00:02, 15.83it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  94%|█████████▍| 529/563 [00:33<00:02, 15.87it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  95%|█████████▍| 533/563 [00:33<00:01, 15.91it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Validating:  68%|██████▊   | 64/94 [00:04<00:01, 21.49it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 537/563 [00:33<00:01, 15.96it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  96%|█████████▌| 541/563 [00:33<00:01, 15.95it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  97%|█████████▋| 545/563 [00:34<00:01, 16.00it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  98%|█████████▊| 549/563 [00:34<00:00, 16.03it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Validating:  85%|████████▌ | 80/94 [00:05<00:00, 21.68it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 553/563 [00:34<00:00, 16.07it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2:  99%|█████████▉| 557/563 [00:34<00:00, 16.12it/s, loss=0.425, v_num=23, val_loss_epoch=0.815, training_loss_step=0.493, training_loss_epoch=0.904, val_loss_step=0.295]\n",
      "Epoch 2: 100%|██████████| 563/563 [00:35<00:00, 16.08it/s, loss=0.425, v_num=23, val_loss_epoch=0.615, training_loss_step=0.281, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  83%|████████▎ | 469/563 [00:29<00:05, 15.81it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 472/563 [00:31<00:06, 15.09it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  84%|████████▍ | 475/563 [00:31<00:05, 15.14it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  85%|████████▌ | 479/563 [00:31<00:05, 15.14it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Validating:  11%|█         | 10/94 [00:01<00:10,  8.06it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 483/563 [00:31<00:05, 15.20it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  87%|████████▋ | 487/563 [00:32<00:04, 15.20it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  87%|████████▋ | 491/563 [00:32<00:04, 15.27it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Validating:  23%|██▎       | 22/94 [00:02<00:04, 16.76it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 495/563 [00:32<00:04, 15.28it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  89%|████████▊ | 499/563 [00:32<00:04, 15.34it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  89%|████████▉ | 503/563 [00:32<00:03, 15.32it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  90%|█████████ | 507/563 [00:32<00:03, 15.37it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Validating:  40%|████      | 38/94 [00:03<00:02, 20.46it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 511/563 [00:33<00:03, 15.38it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  91%|█████████▏| 515/563 [00:33<00:03, 15.43it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  92%|█████████▏| 519/563 [00:33<00:02, 15.46it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Validating:  53%|█████▎    | 50/94 [00:03<00:02, 20.68it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 523/563 [00:33<00:02, 15.50it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  94%|█████████▎| 527/563 [00:34<00:02, 15.49it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Validating:  63%|██████▎   | 59/94 [00:04<00:01, 17.99it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 531/563 [00:34<00:02, 15.52it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  95%|█████████▌| 535/563 [00:34<00:01, 15.54it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  96%|█████████▌| 539/563 [00:34<00:01, 15.60it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  96%|█████████▋| 543/563 [00:34<00:01, 15.64it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  97%|█████████▋| 547/563 [00:34<00:01, 15.67it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Validating:  83%|████████▎ | 78/94 [00:05<00:00, 20.95it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 551/563 [00:35<00:00, 15.71it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3:  99%|█████████▉| 556/563 [00:35<00:00, 15.80it/s, loss=0.314, v_num=23, val_loss_epoch=0.615, training_loss_step=0.291, training_loss_epoch=0.485, val_loss_step=0.184]\n",
      "Epoch 3: 100%|██████████| 563/563 [00:35<00:00, 15.76it/s, loss=0.314, v_num=23, val_loss_epoch=0.488, training_loss_step=0.277, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  83%|████████▎ | 470/563 [00:29<00:05, 15.74it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 473/563 [00:31<00:05, 15.05it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  85%|████████▍ | 478/563 [00:31<00:05, 15.16it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  10%|▉         | 9/94 [00:01<00:12,  7.05it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 483/563 [00:31<00:05, 15.16it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  16%|█▌        | 15/94 [00:02<00:06, 12.53it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 488/563 [00:32<00:04, 15.17it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  88%|████████▊ | 493/563 [00:32<00:04, 15.26it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  27%|██▋       | 25/94 [00:02<00:04, 14.25it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 498/563 [00:32<00:04, 15.24it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  89%|████████▉ | 503/563 [00:33<00:03, 15.23it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  36%|███▌      | 34/94 [00:03<00:03, 15.69it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 508/563 [00:33<00:03, 15.32it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  91%|█████████ | 513/563 [00:33<00:03, 15.34it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  48%|████▊     | 45/94 [00:03<00:02, 19.74it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 518/563 [00:33<00:02, 15.39it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  93%|█████████▎| 523/563 [00:33<00:02, 15.43it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  59%|█████▊    | 55/94 [00:04<00:01, 22.59it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 528/563 [00:34<00:02, 15.43it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  95%|█████████▍| 533/563 [00:34<00:01, 15.51it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  69%|██████▉   | 65/94 [00:04<00:01, 19.02it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 538/563 [00:34<00:01, 15.51it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  96%|█████████▋| 543/563 [00:34<00:01, 15.56it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  97%|█████████▋| 548/563 [00:35<00:00, 15.62it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Validating:  85%|████████▌ | 80/94 [00:05<00:00, 24.51it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 553/563 [00:35<00:00, 15.67it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4:  99%|█████████▉| 558/563 [00:35<00:00, 15.76it/s, loss=0.224, v_num=23, val_loss_epoch=0.488, training_loss_step=0.213, training_loss_epoch=0.320, val_loss_step=0.0933]\n",
      "Epoch 4: 100%|██████████| 563/563 [00:35<00:00, 15.69it/s, loss=0.224, v_num=23, val_loss_epoch=0.433, training_loss_step=0.277, training_loss_epoch=0.233, val_loss_step=0.150] \n",
      "Epoch 5:  83%|████████▎ | 469/563 [00:29<00:06, 15.64it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▎ | 471/563 [00:31<00:06, 14.95it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  84%|████████▍ | 474/563 [00:31<00:05, 14.98it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  85%|████████▍ | 477/563 [00:31<00:05, 15.02it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  85%|████████▌ | 480/563 [00:31<00:05, 15.06it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  86%|████████▌ | 484/563 [00:32<00:05, 15.11it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  87%|████████▋ | 488/563 [00:32<00:04, 15.08it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  87%|████████▋ | 492/563 [00:32<00:04, 15.13it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Validating:  24%|██▍       | 23/94 [00:02<00:04, 16.00it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 496/563 [00:32<00:04, 15.15it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  89%|████████▉ | 500/563 [00:32<00:04, 15.21it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  90%|████████▉ | 504/563 [00:33<00:03, 15.22it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  90%|█████████ | 508/563 [00:33<00:03, 15.28it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Validating:  41%|████▏     | 39/94 [00:03<00:02, 20.97it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 512/563 [00:33<00:03, 15.27it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  92%|█████████▏| 516/563 [00:33<00:03, 15.33it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  92%|█████████▏| 520/563 [00:33<00:02, 15.32it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  93%|█████████▎| 524/563 [00:34<00:02, 15.36it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Validating:  59%|█████▊    | 55/94 [00:04<00:01, 20.60it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 528/563 [00:34<00:02, 15.39it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  94%|█████████▍| 532/563 [00:34<00:02, 15.44it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  95%|█████████▌| 536/563 [00:34<00:01, 15.40it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  96%|█████████▌| 541/563 [00:34<00:01, 15.49it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Validating:  77%|███████▋  | 72/94 [00:04<00:00, 22.25it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 546/563 [00:35<00:01, 15.48it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  98%|█████████▊| 551/563 [00:35<00:00, 15.51it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5:  99%|█████████▉| 556/563 [00:35<00:00, 15.61it/s, loss=0.166, v_num=23, val_loss_epoch=0.433, training_loss_step=0.124, training_loss_epoch=0.233, val_loss_step=0.150]\n",
      "Epoch 5: 100%|██████████| 563/563 [00:36<00:00, 15.59it/s, loss=0.166, v_num=23, val_loss_epoch=0.382, training_loss_step=0.245, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  83%|████████▎ | 470/563 [00:29<00:05, 15.67it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\n",
      "Validating:   1%|          | 1/94 [00:01<02:11,  1.41s/it]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 473/563 [00:31<00:06, 14.99it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  85%|████████▍ | 476/563 [00:31<00:05, 15.03it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  85%|████████▌ | 479/563 [00:31<00:05, 15.07it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  86%|████████▌ | 482/563 [00:31<00:05, 15.09it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  86%|████████▌ | 485/563 [00:32<00:05, 15.13it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  87%|████████▋ | 488/563 [00:32<00:04, 15.14it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  87%|████████▋ | 491/563 [00:32<00:04, 15.13it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  88%|████████▊ | 496/563 [00:32<00:04, 15.20it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Validating:  30%|██▉       | 28/94 [00:02<00:04, 15.17it/s]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 501/563 [00:32<00:04, 15.19it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  90%|████████▉ | 506/563 [00:33<00:03, 15.24it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Validating:  40%|████      | 38/94 [00:03<00:02, 19.23it/s]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 511/563 [00:33<00:03, 15.30it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  92%|█████████▏| 516/563 [00:33<00:03, 15.32it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Validating:  50%|█████     | 47/94 [00:03<00:02, 20.38it/s]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 521/563 [00:34<00:02, 15.32it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  93%|█████████▎| 526/563 [00:34<00:02, 15.40it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Validating:  61%|██████    | 57/94 [00:04<00:01, 22.97it/s]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 531/563 [00:34<00:02, 15.41it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Validating:  67%|██████▋   | 63/94 [00:04<00:01, 20.30it/s]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 536/563 [00:34<00:01, 15.44it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  96%|█████████▌| 541/563 [00:34<00:01, 15.50it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Validating:  77%|███████▋  | 72/94 [00:04<00:00, 22.80it/s]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 546/563 [00:35<00:01, 15.53it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6:  98%|█████████▊| 551/563 [00:35<00:00, 15.61it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Validating:  87%|████████▋ | 82/94 [00:05<00:00, 21.83it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 556/563 [00:35<00:00, 15.65it/s, loss=0.133, v_num=23, val_loss_epoch=0.382, training_loss_step=0.090, training_loss_epoch=0.169, val_loss_step=0.151]\n",
      "Epoch 6: 100%|██████████| 563/563 [00:36<00:00, 15.61it/s, loss=0.133, v_num=23, val_loss_epoch=0.373, training_loss_step=0.163, training_loss_epoch=0.130, val_loss_step=0.192]\n",
      "Epoch 6: 100%|██████████| 563/563 [00:36<00:00, 15.61it/s, loss=0.133, v_num=23, val_loss_epoch=0.373, training_loss_step=0.163, training_loss_epoch=0.130, val_loss_step=0.192]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=intent_pos_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "latest-birmingham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 141/141 [00:06<00:00, 22.78it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = IntentPosClassifier.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "trainer.test(model, datamodule=intent_pos_dm)\n",
    "test_preds = model.test_preds\n",
    "idx_to_intent = {idx: intent for intent, idx in intent_labels.items()}\n",
    "preds = model.process_logits(test_preds['logits'], idx_to_intent)\n",
    "ids = test_preds['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vital-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-10 12:43:35,691 - __main__ - INFO - Intent predictions written to ../ADL21-HW1/data/intent/intent_mt_preds_v20.csv\n"
     ]
    }
   ],
   "source": [
    "write_preds_to_csv(task='intent', ids=ids, preds=preds, fname=\"intent_mt_preds_v20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "measured-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "going-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "brazilian-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_intent = {idx: intent for intent, idx in intent_labels.items()}\n",
    "preds = [idx_to_intent[p] for p in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "distinguished-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.LongTensor([1, 2, 3])\n",
    "b = torch.LongTensor([4, 5, 6, 9, 10])\n",
    "c = torch.LongTensor([7])\n",
    "# a = torch.ones(10, 10)\n",
    "# b = torch.ones(25, 10)\n",
    "# a = torch.ones(9, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "historic-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "sought-martial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a', 2: 'b', 3: 'c', 4: 'd'}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    1: 'a',\n",
    "    2: 'b',\n",
    "    **{3: 'c', 4: 'd'}\n",
    "}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "infrared-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 4,  5,  6,  9, 10]), tensor([1, 2, 3]), tensor([7])]\n",
      "[tensor([1, 2, 3]), tensor([ 4,  5,  6,  9, 10]), tensor([7])]\n"
     ]
    }
   ],
   "source": [
    "unpacked = [list() for _ in range(len(packed.unsorted_indices))]\n",
    "left = 0\n",
    "right = 0\n",
    "for batch in packed.batch_sizes:\n",
    "    right = left + batch\n",
    "    window = packed.data[left: right]        \n",
    "    for idx, item in enumerate(window):\n",
    "        unpacked[idx].append(item)\n",
    "    left = right\n",
    "unpacked = [torch.stack(u) for u in unpacked]\n",
    "print(unpacked)\n",
    "order = packed.unsorted_indices.tolist()\n",
    "unpacked = [unpacked[idx] for idx in order]\n",
    "print(unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "general-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "permute = [packed.unsorted_indices.tolist().index(i) for i in range(len(packed.unsorted_indices))]\n",
    "print(permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "flexible-allen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 2, 3]), tensor([ 4,  5,  6,  9, 10]), tensor([7])]\n"
     ]
    }
   ],
   "source": [
    "unpacked = [unpacked[idx] for idx in permute]\n",
    "print(unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "blocked-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(300, 5, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "beautiful-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = gru(packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "passing-stable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 10])\n",
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "brown-carter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([hidden[0,...], hidden[1,...]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "numerous-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.view(3, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "blank-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3463, -0.0763,  0.2259,  0.1647, -0.2322, -0.0119,  0.1743, -0.0364,\n",
      "         0.2349, -0.0128], grad_fn=<SliceBackward>)\n",
      "tensor([-0.3463, -0.0763,  0.2259,  0.1647, -0.2322], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0,-1,:])\n",
    "print(hidden[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "three-kazakhstan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 10])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(out, batch_first=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "psychological-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.Tensor([1, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "favorite-background",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1592,  0.1634, -0.7492, -0.6678,  0.6098],\n",
       "        [ 0.0978,  0.2586, -0.1639, -0.9648,  0.6199],\n",
       "        [ 0.0724,  0.3100, -0.1748, -0.9578,  0.2774]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.view(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "japanese-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-21 02:06:47,328 - __main__ - INFO - Loading GloVe embeddings...\n",
      "2021-03-21 02:08:37,989 - __main__ - INFO - Done!\n"
     ]
    }
   ],
   "source": [
    "glove = IntentDataset._load_glove('../../data/glove.840B.300d.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "czech-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = IntentDataset(\"../ADL21-HW1/data/intent/train.json\", \"../data/intents_to_idx.json\", glove_obj=glove )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "rational-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [torch.randn(3) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "scenic-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "internal-swiss",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=0, std=1, size=(5, 25)).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "quantitative-amount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove['jump'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "balanced-immigration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-18 00:23:09,648 - __main__ - INFO - Loading Glove embeddings...\n",
      "2021-03-18 00:25:02,845 - __main__ - INFO - Glove embeddings loaded.\n"
     ]
    }
   ],
   "source": [
    "g = build_glove('../../data/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "worst-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../../data/glove.840B.300d.gz', 'wb') as f:\n",
    "    pickle.dump(g, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "actual-chicago",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('../../data/crawl-300d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "rocky-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x7f6c50bd7430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.reduce_model(ft, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "minor-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_model('../../data/crawl-100d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tender-jersey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('../../data/crawl-100d-2M-subword.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sublime-baghdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    }
   ],
   "source": [
    "with open('../ADL21-HW1/data/intent/test.json') as f:\n",
    "    train = json.load(f)\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-future",
   "metadata": {},
   "source": [
    "# Slot Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-nashville",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hybrid-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingDataset(Dataset):\n",
    "    def __init__(self, data_path: str, train: bool, mapping: Dict[str, int], glove: Optional[Dict[str, np.array]] = None, glove_path: str = \"../../data/glove.840B.300d.gz\", unk_token_strategy='average'):\n",
    "        with open(data_path) as f: \n",
    "            self.data = json.load(f)\n",
    "        self.tag_to_idx = mapping\n",
    "        self.train = train\n",
    "        self.glove = glove\n",
    "        self.unk_token_strategy = unk_token_strategy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tokens = sample['tokens']\n",
    "        _id = sample['id']\n",
    "        tokens = self.convert_to_vectors(tokens, _id)\n",
    "        length = len(tokens)\n",
    "        _id = [sample['id']] * length\n",
    "        out = {\n",
    "            'id': _id,\n",
    "            'tokens': tokens,\n",
    "            'length': length\n",
    "        }\n",
    "        if self.train:\n",
    "            tags = sample['tags']\n",
    "            tags = [self.tag_to_idx[t] for t in tags]\n",
    "            out['tags'] = tags\n",
    "            assert len(tags) == len(tokens)\n",
    "        return out\n",
    "        \n",
    "    def convert_to_vectors(self, text, _id):\n",
    "        vectors = []\n",
    "        missing_idx = []\n",
    "        \n",
    "        for idx, tok in enumerate(text):\n",
    "            try:\n",
    "                vector = torch.from_numpy(self.glove[tok]).float()\n",
    "            except KeyError:\n",
    "#                 avg = torch.mean(torch.stack(vectors), axis=0)\n",
    "                missing_idx.append(idx)\n",
    "                vectors.append(torch.zeros(300))\n",
    "#                 vectors.append(avg)\n",
    "                continue\n",
    "            else:\n",
    "                vectors.append(vector)\n",
    "                \n",
    "        if len(vectors) == len(missing_idx):\n",
    "            return torch.stack(vectors)\n",
    "        \n",
    "        if self.unk_token_strategy == 'ignore':\n",
    "            return torch.stack(vectors)\n",
    "        \n",
    "        elif self.unk_token_strategy == 'average':\n",
    "            if missing_idx:\n",
    "                vectors = self._average_tokens(vectors, missing_idx)\n",
    "                \n",
    "        vectors = torch.stack(vectors)\n",
    "        if torch.isnan(vectors).sum() > 0:\n",
    "            print('NaN in embeddings!')\n",
    "            print(_id)\n",
    "            raise Exception\n",
    "                \n",
    "        return vectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def _average_tokens(vectors: list, missing_idxs: list, window: int = 2):\n",
    "        for m in missing_idxs:\n",
    "            avg = vectors[max(m-window, 0): m] + vectors[m + 1: m+1+window]\n",
    "            if not avg:\n",
    "                avg = torch.stack(vectors)\n",
    "            else:\n",
    "                avg = torch.stack(avg)\n",
    "            if avg.sum() == 0:\n",
    "                vectors[m] = torch.zeros(300)\n",
    "                continue\n",
    "            avg = avg[avg.nonzero(as_tuple=True)].view(-1, avg.shape[1])\n",
    "            avg = torch.mean(avg[avg.nonzero(as_tuple=True)].view(-1, avg.shape[1]), axis=0)\n",
    "            vectors[m] = avg\n",
    "        \n",
    "        return vectors\n",
    "            \n",
    "        \n",
    "class TaggingDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"../ADL21-HW1/data/slot/\", mapping: str = \"../data/tags_to_idx.json\", embedding_obj: Optional[Dict[str, np.array]] = None, embedding_dir: str = \"../../data/glove.840B.300d.gz\", batch_size: int = 32, pin_memory: bool = True):\n",
    "        super().__init__()\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.batch_size = batch_size\n",
    "        self.pin_memory = pin_memory\n",
    "        with open(mapping) as f:\n",
    "            self.tag_to_idx = json.load(f)\n",
    "        if embedding_obj:\n",
    "            self.emb = embedding_obj\n",
    "        else:\n",
    "            self.emb = self._load_glove(embedding_dir)\n",
    "        \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.tag_train = TaggingDataset(\n",
    "                data_path=self.data_dir.joinpath('train.json'), \n",
    "                train=True,\n",
    "                mapping=self.tag_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "            self.tag_val = TaggingDataset(\n",
    "                data_path=self.data_dir.joinpath('eval.json'), \n",
    "                train=True,\n",
    "                mapping=self.tag_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "        elif stage == \"test\" or stage is None:\n",
    "            self.tag_test = TaggingDataset(\n",
    "                data_path=self.data_dir.joinpath('test.json'), \n",
    "                train=False,\n",
    "                mapping=self.tag_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.tag_train, batch_size=self.batch_size, num_workers=8, pin_memory=self.pin_memory, collate_fn=self._collate_fn(is_test=False), shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.tag_val, batch_size=self.batch_size, num_workers=8, pin_memory=self.pin_memory, collate_fn=self._collate_fn(is_test=False))\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.tag_test, batch_size=self.batch_size, num_workers=8, pin_memory=self.pin_memory, collate_fn=self._collate_fn(is_test=True))\n",
    "        \n",
    "    @staticmethod\n",
    "    def _collate_fn(is_test):\n",
    "        def collate_fn(batch):\n",
    "            out = {}\n",
    "            _id = [b['id'] for b in batch]\n",
    "            tokens = [b['tokens'] for b in batch]\n",
    "            length = torch.LongTensor([b['length'] for b in batch])\n",
    "            assert all(l == len(t) for l, t in zip(length, tokens))\n",
    "            tokens = pad_sequence(tokens, batch_first=True)\n",
    "            if not is_test:\n",
    "                tags = [torch.LongTensor(b['tags']) for b in batch]\n",
    "                out['tags'] = pad_sequence(tags, batch_first=True, padding_value=-1)\n",
    "#                 tag_lengths = [len(t) for t in tags]\n",
    "#                 out['tag_lengths'] = tag_lengths\n",
    "\n",
    "            out['id'] = _id\n",
    "            out['tokens'] = tokens\n",
    "            out['length'] = length\n",
    "            return out\n",
    "        return collate_fn\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_glove(fpath: str) -> Dict[str, torch.FloatTensor]:\n",
    "        logger.info(\"Loading GloVe embeddings...\")\n",
    "        with gzip.open(fpath, 'rb') as f:\n",
    "            emb = pickle.load(f)\n",
    "        logger.info(\"Done!\")\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-defeat",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interior-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_labels: int, hidden_size: int = 128, num_layers: int = 3, bidirectional: bool = True, lr: int = 1e-5, dropout=0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = 2 if bidirectional else 1\n",
    "        self.lr = lr\n",
    "        self.dropout_prob = dropout\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=300, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=bidirectional, \n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.hidden_to_labels = nn.Linear(self.hidden_size * self.bidirectional, num_labels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.save_hyperparameters()\n",
    "        self.test_preds = {\n",
    "            'ids': [],\n",
    "            'logits': []\n",
    "        }\n",
    "        self.val_preds = {\n",
    "            'ids': [],\n",
    "            'preds': []\n",
    "        }\n",
    "        \n",
    "    def forward(self, inpt):\n",
    "        samples = inpt['tokens'].to('cuda')\n",
    "        if torch.isnan(samples).sum() > 0:\n",
    "            print(f\"NaN in samples!\")\n",
    "            raise Exception\n",
    "        lengths = inpt['length'].to('cpu')\n",
    "        batch_size = samples.shape[0]\n",
    "        samples = pack_padded_sequence(samples, lengths, batch_first=True, enforce_sorted=False)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(samples, hidden)\n",
    "        out, out_lens = pad_packed_sequence(out, batch_first=True)\n",
    "#         out = out.view(-1, out.shape[-1])\n",
    "        if torch.isnan(out).sum() > 0:\n",
    "            print(f\"NaN in out!\")\n",
    "            raise Exception\n",
    "        logits = self.dropout(self.hidden_to_labels(out))\n",
    "#         print(f'LENGTHS: {lengths}')\n",
    "#         print(f'LOGITS: {logits.shape}')\n",
    "        \n",
    "#         assert lengths == logits.shape[1]\n",
    "#         logits = logits.permute(0, 2, 1)  # must move classes to second dimension\n",
    "        return logits\n",
    "        \n",
    "    def _shared_step(self, batch):\n",
    "        ids = batch['id']\n",
    "        tags = batch['tags']\n",
    "        logits = self(batch)\n",
    "        logits = logits.permute(0, 2, 1)\n",
    "#         logger.info(f\"TAGS: {tags.shape}\")\n",
    "#         logger.info(f\"LOGITS: {logits.shape}\")\n",
    "#         logits = logits.reshape(-1, logits.shape[-1])\n",
    "#         tags = tags.view(-1)\n",
    "#         logger.info(f\"TAGS: {tags.shape}\")\n",
    "#         logger.info(f\"LOGITS: {logits.shape}\")\n",
    "        loss = F.cross_entropy(logits, tags, ignore_index=-1)\n",
    "#         loss = F.nll_loss(F.log_softmax(logits, dim=1), tags, ignore_index=-1)\n",
    "        return loss\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self.log('training_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._shared_step(batch)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids = batch['id']\n",
    "        logits = self(batch)\n",
    "        self.test_preds['ids'].extend(ids)\n",
    "        self.test_preds['logits'].extend(logits)\n",
    "        \n",
    "    def process_logits(self, logits, idx2int):\n",
    "        preds = torch.stack(logits)\n",
    "        preds = preds.argmax(dim=1).tolist()\n",
    "        preds = [idx2int[p] for p in preds]\n",
    "        return preds\n",
    "            \n",
    "    def init_hidden(self, batch_size):\n",
    "#         return torch.normal(mean=0, std=1, size=(self.bidirectional * self.num_layers, batch_size, self.hidden_size)).to('cpu')\n",
    "        return torch.normal(mean=0, std=1, size=(self.bidirectional * self.num_layers, batch_size, self.hidden_size)).to('cuda')\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "suitable-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_mapping('../ADL21-HW1/data/slot/train.json', 'tags', '../data/tags_to_idx.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hindu-ideal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-05 22:01:54,557 - __main__ - INFO - Loading GloVe embeddings...\n",
      "2021-04-05 22:02:22,630 - __main__ - INFO - Done!\n"
     ]
    }
   ],
   "source": [
    "# glove = TaggingDataModule._load_glove('../../data/glove.840B.300d.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "standard-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dm = TaggingDataModule(embedding_obj=glove, batch_size=64)\n",
    "tag_dm.prepare_data()\n",
    "tag_dm.setup(stage='fit')\n",
    "labels = tag_dm.tag_to_idx\n",
    "model = TaggingClassifier(num_labels=len(labels), lr=1e-4, hidden_size=512, dropout=0, num_layers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "inclusive-sellers",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dclian/adl/hw1/notebooks/tagging_lightning_logs\n"
     ]
    }
   ],
   "source": [
    "logging_dir = Path('.').joinpath('tagging_lightning_logs')\n",
    "print(str(logging_dir.resolve()))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "#     dirpath=logging_dir.resolve(),\n",
    "    filename='tagging-{epoch:02d}-{training_loss:.2f}-{val_loss:.2f}',\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    \n",
    "#     auto_lr_find=True,\n",
    "    gpus=1,\n",
    "#     gradient_clip_val=1,\n",
    "    weights_summary='full',\n",
    "#     precision=16,\n",
    "#     track_grad_norm=2,\n",
    "    default_root_dir=str(logging_dir.resolve()),\n",
    "    callbacks=[EarlyStopping(monitor='val_loss'), checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "proved-documentation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name             | Type    | Params\n",
      "---------------------------------------------\n",
      "0 | rnn              | GRU     | 35.6 M\n",
      "1 | hidden_to_labels | Linear  | 9.2 K \n",
      "2 | dropout          | Dropout | 0     \n",
      "---------------------------------------------\n",
      "35.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "35.6 M    Total params\n",
      "142.332   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  88%|████████▊ | 115/130 [00:05<00:00, 20.77it/s, loss=0.818, v_num=36, val_loss_epoch=2.200, training_loss_step=0.756]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 118/130 [00:06<00:00, 19.41it/s, loss=0.818, v_num=36, val_loss_epoch=2.200, training_loss_step=0.756]\n",
      "Epoch 0:  95%|█████████▌| 124/130 [00:06<00:00, 20.06it/s, loss=0.818, v_num=36, val_loss_epoch=2.200, training_loss_step=0.756]\n",
      "Epoch 0: 100%|██████████| 130/130 [00:06<00:00, 20.27it/s, loss=0.818, v_num=36, val_loss_epoch=0.766, training_loss_step=0.746, training_loss_epoch=0.913, val_loss_step=0.829]\n",
      "Epoch 1:  88%|████████▊ | 114/130 [00:05<00:00, 20.44it/s, loss=0.504, v_num=36, val_loss_epoch=0.766, training_loss_step=0.510, training_loss_epoch=0.913, val_loss_step=0.829]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 120/130 [00:06<00:00, 19.45it/s, loss=0.504, v_num=36, val_loss_epoch=0.766, training_loss_step=0.510, training_loss_epoch=0.913, val_loss_step=0.829]\n",
      "Epoch 1:  97%|█████████▋| 126/130 [00:06<00:00, 20.10it/s, loss=0.504, v_num=36, val_loss_epoch=0.766, training_loss_step=0.510, training_loss_epoch=0.913, val_loss_step=0.829]\n",
      "Epoch 1: 100%|██████████| 130/130 [00:06<00:00, 20.13it/s, loss=0.504, v_num=36, val_loss_epoch=0.458, training_loss_step=0.350, training_loss_epoch=0.620, val_loss_step=0.494]\n",
      "Epoch 2:  88%|████████▊ | 114/130 [00:05<00:00, 20.29it/s, loss=0.372, v_num=36, val_loss_epoch=0.458, training_loss_step=0.437, training_loss_epoch=0.620, val_loss_step=0.494]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 120/130 [00:06<00:00, 19.27it/s, loss=0.372, v_num=36, val_loss_epoch=0.458, training_loss_step=0.437, training_loss_epoch=0.620, val_loss_step=0.494]\n",
      "Epoch 2:  97%|█████████▋| 126/130 [00:06<00:00, 19.91it/s, loss=0.372, v_num=36, val_loss_epoch=0.458, training_loss_step=0.437, training_loss_epoch=0.620, val_loss_step=0.494]\n",
      "Epoch 2: 100%|██████████| 130/130 [00:06<00:00, 20.01it/s, loss=0.372, v_num=36, val_loss_epoch=0.332, training_loss_step=0.331, training_loss_epoch=0.399, val_loss_step=0.307]\n",
      "Epoch 3:  88%|████████▊ | 114/130 [00:05<00:00, 20.49it/s, loss=0.262, v_num=36, val_loss_epoch=0.332, training_loss_step=0.266, training_loss_epoch=0.399, val_loss_step=0.307]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 120/130 [00:06<00:00, 19.51it/s, loss=0.262, v_num=36, val_loss_epoch=0.332, training_loss_step=0.266, training_loss_epoch=0.399, val_loss_step=0.307]\n",
      "Epoch 3:  97%|█████████▋| 126/130 [00:06<00:00, 20.15it/s, loss=0.262, v_num=36, val_loss_epoch=0.332, training_loss_step=0.266, training_loss_epoch=0.399, val_loss_step=0.307]\n",
      "Epoch 3: 100%|██████████| 130/130 [00:06<00:00, 20.21it/s, loss=0.262, v_num=36, val_loss_epoch=0.263, training_loss_step=0.123, training_loss_epoch=0.297, val_loss_step=0.248]\n",
      "Epoch 4:  88%|████████▊ | 114/130 [00:05<00:00, 20.61it/s, loss=0.221, v_num=36, val_loss_epoch=0.263, training_loss_step=0.200, training_loss_epoch=0.297, val_loss_step=0.248]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 120/130 [00:06<00:00, 19.62it/s, loss=0.221, v_num=36, val_loss_epoch=0.263, training_loss_step=0.200, training_loss_epoch=0.297, val_loss_step=0.248]\n",
      "Epoch 4:  97%|█████████▋| 126/130 [00:06<00:00, 20.26it/s, loss=0.221, v_num=36, val_loss_epoch=0.263, training_loss_step=0.200, training_loss_epoch=0.297, val_loss_step=0.248]\n",
      "Epoch 4: 100%|██████████| 130/130 [00:06<00:00, 20.34it/s, loss=0.221, v_num=36, val_loss_epoch=0.218, training_loss_step=0.086, training_loss_epoch=0.244, val_loss_step=0.189]\n",
      "Epoch 5:  88%|████████▊ | 114/130 [00:05<00:00, 20.47it/s, loss=0.203, v_num=36, val_loss_epoch=0.218, training_loss_step=0.176, training_loss_epoch=0.244, val_loss_step=0.189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 120/130 [00:06<00:00, 19.48it/s, loss=0.203, v_num=36, val_loss_epoch=0.218, training_loss_step=0.176, training_loss_epoch=0.244, val_loss_step=0.189]\n",
      "Epoch 5:  97%|█████████▋| 126/130 [00:06<00:00, 20.12it/s, loss=0.203, v_num=36, val_loss_epoch=0.218, training_loss_step=0.176, training_loss_epoch=0.244, val_loss_step=0.189]\n",
      "Epoch 5: 100%|██████████| 130/130 [00:06<00:00, 20.13it/s, loss=0.203, v_num=36, val_loss_epoch=0.199, training_loss_step=0.208, training_loss_epoch=0.204, val_loss_step=0.206]\n",
      "Epoch 6:  88%|████████▊ | 114/130 [00:05<00:00, 20.50it/s, loss=0.181, v_num=36, val_loss_epoch=0.199, training_loss_step=0.127, training_loss_epoch=0.204, val_loss_step=0.206]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 120/130 [00:06<00:00, 19.48it/s, loss=0.181, v_num=36, val_loss_epoch=0.199, training_loss_step=0.127, training_loss_epoch=0.204, val_loss_step=0.206]\n",
      "Epoch 6:  97%|█████████▋| 126/130 [00:06<00:00, 20.12it/s, loss=0.181, v_num=36, val_loss_epoch=0.199, training_loss_step=0.127, training_loss_epoch=0.204, val_loss_step=0.206]\n",
      "Epoch 6: 100%|██████████| 130/130 [00:06<00:00, 20.10it/s, loss=0.181, v_num=36, val_loss_epoch=0.192, training_loss_step=0.279, training_loss_epoch=0.184, val_loss_step=0.195]\n",
      "Epoch 7:  88%|████████▊ | 114/130 [00:05<00:00, 20.33it/s, loss=0.167, v_num=36, val_loss_epoch=0.192, training_loss_step=0.240, training_loss_epoch=0.184, val_loss_step=0.195] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 120/130 [00:06<00:00, 19.37it/s, loss=0.167, v_num=36, val_loss_epoch=0.192, training_loss_step=0.240, training_loss_epoch=0.184, val_loss_step=0.195]\n",
      "Epoch 7:  97%|█████████▋| 126/130 [00:06<00:00, 20.01it/s, loss=0.167, v_num=36, val_loss_epoch=0.192, training_loss_step=0.240, training_loss_epoch=0.184, val_loss_step=0.195]\n",
      "Epoch 7: 100%|██████████| 130/130 [00:06<00:00, 20.07it/s, loss=0.167, v_num=36, val_loss_epoch=0.165, training_loss_step=0.275, training_loss_epoch=0.166, val_loss_step=0.179]\n",
      "Epoch 8:  88%|████████▊ | 114/130 [00:05<00:00, 20.44it/s, loss=0.155, v_num=36, val_loss_epoch=0.165, training_loss_step=0.111, training_loss_epoch=0.166, val_loss_step=0.179]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 120/130 [00:06<00:00, 19.39it/s, loss=0.155, v_num=36, val_loss_epoch=0.165, training_loss_step=0.111, training_loss_epoch=0.166, val_loss_step=0.179]\n",
      "Epoch 8:  97%|█████████▋| 126/130 [00:06<00:00, 20.04it/s, loss=0.155, v_num=36, val_loss_epoch=0.165, training_loss_step=0.111, training_loss_epoch=0.166, val_loss_step=0.179]\n",
      "Epoch 8: 100%|██████████| 130/130 [00:06<00:00, 20.13it/s, loss=0.155, v_num=36, val_loss_epoch=0.166, training_loss_step=0.159, training_loss_epoch=0.153, val_loss_step=0.161]\n",
      "Epoch 9:  88%|████████▊ | 114/130 [00:05<00:00, 20.39it/s, loss=0.139, v_num=36, val_loss_epoch=0.166, training_loss_step=0.121, training_loss_epoch=0.153, val_loss_step=0.161] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 120/130 [00:06<00:00, 19.38it/s, loss=0.139, v_num=36, val_loss_epoch=0.166, training_loss_step=0.121, training_loss_epoch=0.153, val_loss_step=0.161]\n",
      "Epoch 9:  97%|█████████▋| 126/130 [00:06<00:00, 20.02it/s, loss=0.139, v_num=36, val_loss_epoch=0.166, training_loss_step=0.121, training_loss_epoch=0.153, val_loss_step=0.161]\n",
      "Epoch 9: 100%|██████████| 130/130 [00:06<00:00, 20.04it/s, loss=0.139, v_num=36, val_loss_epoch=0.155, training_loss_step=0.102, training_loss_epoch=0.144, val_loss_step=0.140]\n",
      "Epoch 10:  88%|████████▊ | 114/130 [00:05<00:00, 20.26it/s, loss=0.128, v_num=36, val_loss_epoch=0.155, training_loss_step=0.152, training_loss_epoch=0.144, val_loss_step=0.140] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 120/130 [00:06<00:00, 19.31it/s, loss=0.128, v_num=36, val_loss_epoch=0.155, training_loss_step=0.152, training_loss_epoch=0.144, val_loss_step=0.140]\n",
      "Epoch 10:  97%|█████████▋| 126/130 [00:06<00:00, 19.95it/s, loss=0.128, v_num=36, val_loss_epoch=0.155, training_loss_step=0.152, training_loss_epoch=0.144, val_loss_step=0.140]\n",
      "Epoch 10: 100%|██████████| 130/130 [00:06<00:00, 19.96it/s, loss=0.128, v_num=36, val_loss_epoch=0.153, training_loss_step=0.0929, training_loss_epoch=0.136, val_loss_step=0.177]\n",
      "Epoch 11:  88%|████████▊ | 114/130 [00:05<00:00, 20.45it/s, loss=0.149, v_num=36, val_loss_epoch=0.153, training_loss_step=0.157, training_loss_epoch=0.136, val_loss_step=0.177] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 120/130 [00:06<00:00, 19.47it/s, loss=0.149, v_num=36, val_loss_epoch=0.153, training_loss_step=0.157, training_loss_epoch=0.136, val_loss_step=0.177]\n",
      "Epoch 11:  97%|█████████▋| 126/130 [00:06<00:00, 20.12it/s, loss=0.149, v_num=36, val_loss_epoch=0.153, training_loss_step=0.157, training_loss_epoch=0.136, val_loss_step=0.177]\n",
      "Epoch 11: 100%|██████████| 130/130 [00:06<00:00, 20.15it/s, loss=0.149, v_num=36, val_loss_epoch=0.155, training_loss_step=0.178, training_loss_epoch=0.129, val_loss_step=0.168]\n",
      "Epoch 12:  88%|████████▊ | 114/130 [00:05<00:00, 20.25it/s, loss=0.126, v_num=36, val_loss_epoch=0.155, training_loss_step=0.0809, training_loss_epoch=0.129, val_loss_step=0.168]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 120/130 [00:06<00:00, 19.23it/s, loss=0.126, v_num=36, val_loss_epoch=0.155, training_loss_step=0.0809, training_loss_epoch=0.129, val_loss_step=0.168]\n",
      "Epoch 12:  97%|█████████▋| 126/130 [00:06<00:00, 19.87it/s, loss=0.126, v_num=36, val_loss_epoch=0.155, training_loss_step=0.0809, training_loss_epoch=0.129, val_loss_step=0.168]\n",
      "Epoch 12: 100%|██████████| 130/130 [00:06<00:00, 19.89it/s, loss=0.126, v_num=36, val_loss_epoch=0.147, training_loss_step=0.164, training_loss_epoch=0.125, val_loss_step=0.144] \n",
      "Epoch 12: 100%|██████████| 130/130 [00:10<00:00, 11.92it/s, loss=0.126, v_num=36, val_loss_epoch=0.147, training_loss_step=0.164, training_loss_epoch=0.125, val_loss_step=0.144]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, tag_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-edward",
   "metadata": {},
   "source": [
    "## Tagging Multitask Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complex-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingPosDataset(Dataset):\n",
    "    def __init__(self, data_path: str, train: bool, mapping: Dict[str, int], pos_map_path: str = \"../data/pos_to_idx.json\", glove: Optional[Dict[str, np.array]] = None, glove_path: str = \"../../data/glove.840B.300d.gz\", unk_token_strategy='average'):\n",
    "        with open(data_path) as f: \n",
    "            self.data = json.load(f)\n",
    "        self.tag_to_idx = mapping\n",
    "        with open(pos_map_path) as f:\n",
    "            self.pos_to_idx = json.load(f) \n",
    "            self.pos_to_idx['UNK'] = len(self.pos_to_idx)\n",
    "        self.train = train\n",
    "        self.glove = glove\n",
    "        self.nlp = spacy.load('en_core_web_md')\n",
    "        self.unk_token_strategy = unk_token_strategy\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        tokens = sample['tokens']\n",
    "        tokens = [' ' if t == '' else t for t in tokens]\n",
    "        _id = sample['id']\n",
    "        try:\n",
    "            doc = spacy.tokens.Doc(vocab=self.nlp.vocab, words=tokens)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'ID: {_id}')\n",
    "            print(tokens)\n",
    "            raise\n",
    "        tokens = self.convert_to_vectors(tokens, _id)\n",
    "        length = len(tokens)\n",
    "        _id = [sample['id']] * length\n",
    "        out = {\n",
    "            'id': _id,\n",
    "            'tokens': tokens,\n",
    "            'length': length\n",
    "        }\n",
    "        if self.train:\n",
    "            UNK = self.pos_to_idx['UNK']\n",
    "            tags = sample['tags']\n",
    "            tags = [self.tag_to_idx[t] for t in tags]\n",
    "            out['tags'] = tags\n",
    "            pos = [d.tag_ for d in doc]\n",
    "            out['pos'] = [self.pos_to_idx.get(p, UNK) for p in pos]\n",
    "            assert len(pos) == len(tokens)\n",
    "            assert len(tags) == len(tokens)\n",
    "        return out\n",
    "        \n",
    "    def convert_to_vectors(self, text, _id):\n",
    "        vectors = []\n",
    "        missing_idx = []\n",
    "        \n",
    "        for idx, tok in enumerate(text):\n",
    "            try:\n",
    "                vector = torch.from_numpy(self.glove[tok]).float()\n",
    "            except KeyError:\n",
    "#                 avg = torch.mean(torch.stack(vectors), axis=0)\n",
    "                missing_idx.append(idx)\n",
    "                vectors.append(torch.zeros(300))\n",
    "#                 vectors.append(avg)\n",
    "                continue\n",
    "            else:\n",
    "                vectors.append(vector)\n",
    "                \n",
    "        if len(vectors) == len(missing_idx):\n",
    "            return torch.stack(vectors)\n",
    "        \n",
    "        if self.unk_token_strategy == 'ignore':\n",
    "            return torch.stack(vectors)\n",
    "        \n",
    "        elif self.unk_token_strategy == 'average':\n",
    "            if missing_idx:\n",
    "                vectors = self._average_tokens(vectors, missing_idx)\n",
    "                \n",
    "        vectors = torch.stack(vectors)\n",
    "        if torch.isnan(vectors).sum() > 0:\n",
    "            print('NaN in embeddings!')\n",
    "            print(_id)\n",
    "            raise Exception\n",
    "                \n",
    "        return vectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def _average_tokens(vectors: list, missing_idxs: list, window: int = 2):\n",
    "        for m in missing_idxs:\n",
    "            avg = vectors[max(m-window, 0): m] + vectors[m + 1: m+1+window]\n",
    "            if not avg:\n",
    "                avg = torch.stack(vectors)\n",
    "            else:\n",
    "                avg = torch.stack(avg)\n",
    "            if avg.sum() == 0:\n",
    "                vectors[m] = torch.zeros(300)\n",
    "                continue\n",
    "            avg = avg[avg.nonzero(as_tuple=True)].view(-1, avg.shape[1])\n",
    "            avg = torch.mean(avg[avg.nonzero(as_tuple=True)].view(-1, avg.shape[1]), axis=0)\n",
    "            vectors[m] = avg\n",
    "        \n",
    "        return vectors\n",
    "            \n",
    "        \n",
    "class TaggingPosDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"../ADL21-HW1/data/slot/\", mapping: str = \"../data/tags_to_idx.json\", embedding_obj: Optional[Dict[str, np.array]] = None, embedding_dir: str = \"../../data/glove.840B.300d.gz\", batch_size: int = 32, pin_memory: bool = True):\n",
    "        super().__init__()\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.batch_size = batch_size\n",
    "        self.pin_memory = pin_memory\n",
    "        with open(mapping) as f:\n",
    "            self.tag_to_idx = json.load(f)\n",
    "        if embedding_obj:\n",
    "            self.emb = embedding_obj\n",
    "        else:\n",
    "            self.emb = self._load_glove(embedding_dir)\n",
    "        \n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.tag_train = TaggingPosDataset(\n",
    "                data_path=self.data_dir.joinpath('train.json'), \n",
    "                train=True,\n",
    "                mapping=self.tag_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "            self.tag_val = TaggingPosDataset(\n",
    "                data_path=self.data_dir.joinpath('eval.json'), \n",
    "                train=True,\n",
    "                mapping=self.tag_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "            self.pos_to_idx = self.tag_train.pos_to_idx\n",
    "        elif stage == \"test\" or stage is None:\n",
    "            self.tag_test = TaggingPosDataset(\n",
    "                data_path=self.data_dir.joinpath('test.json'), \n",
    "                train=False,\n",
    "                mapping=self.tag_to_idx, \n",
    "                glove=self.emb\n",
    "            ) \n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.tag_train, batch_size=self.batch_size, num_workers=8, pin_memory=self.pin_memory, collate_fn=self._collate_fn(is_test=False), shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.tag_val, batch_size=self.batch_size, num_workers=8, pin_memory=self.pin_memory, collate_fn=self._collate_fn(is_test=False))\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.tag_test, batch_size=self.batch_size, num_workers=8, pin_memory=self.pin_memory, collate_fn=self._collate_fn(is_test=True))\n",
    "        \n",
    "    @staticmethod\n",
    "    def _collate_fn(is_test):\n",
    "        def collate_fn(batch):\n",
    "            out = {}\n",
    "            _id = [b['id'] for b in batch]\n",
    "            tokens = [b['tokens'] for b in batch]\n",
    "            length = torch.LongTensor([b['length'] for b in batch])\n",
    "            assert all(l == len(t) for l, t in zip(length, tokens))\n",
    "            tokens = pad_sequence(tokens, batch_first=True)\n",
    "            if not is_test:\n",
    "                tags = [torch.LongTensor(b['tags']) for b in batch]\n",
    "                pos = [torch.LongTensor(b['pos']) for b in batch]\n",
    "                out['tags'] = pad_sequence(tags, batch_first=True, padding_value=-1)\n",
    "                out['pos'] = pad_sequence(pos, batch_first=True, padding_value=-1)\n",
    "\n",
    "            out['id'] = _id\n",
    "            out['tokens'] = tokens\n",
    "            out['length'] = length\n",
    "            return out\n",
    "        return collate_fn\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_glove(fpath: str) -> Dict[str, torch.FloatTensor]:\n",
    "        logger.info(\"Loading GloVe embeddings...\")\n",
    "        with gzip.open(fpath, 'rb') as f:\n",
    "            emb = pickle.load(f)\n",
    "        logger.info(\"Done!\")\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-perception",
   "metadata": {},
   "source": [
    "## Tagging Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unexpected-myrtle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TaggingPosClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_labels: int, num_pos: int, hidden_size: int = 128, num_layers: int = 3, bidirectional: bool = True, lr: int = 1e-4, dropout=0, loss_ratio=0.7, multitask=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.multitask = multitask\n",
    "        self.loss_ratio = loss_ratio if multitask else 0.0\n",
    "        self.bidirectional = 2 if bidirectional else 1\n",
    "        self.lr = lr\n",
    "        self.dropout_prob = dropout\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=300, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            bidirectional=bidirectional, \n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.hidden_to_labels = nn.Linear(self.hidden_size * self.bidirectional, num_labels)\n",
    "        self.hidden_to_pos = nn.Linear(self.hidden_size * self.bidirectional, num_pos)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.save_hyperparameters()\n",
    "        self.test_preds = {\n",
    "            'ids': [],\n",
    "            'logits': [],\n",
    "            'lengths': [],\n",
    "        }\n",
    "        self.val_preds = {\n",
    "            'ids': [],\n",
    "            'preds': [],\n",
    "            'lengths': [],\n",
    "        }\n",
    "        \n",
    "    def forward(self, inpt):\n",
    "#         samples = inpt['tokens'].to('cuda')\n",
    "        samples = inpt['tokens']\n",
    "        print(samples.shape)\n",
    "        pos = inpt.get('pos')\n",
    "        lengths = inpt['length'].to('cpu')\n",
    "        batch_size = samples.shape[0]\n",
    "        \n",
    "        samples = pack_padded_sequence(samples, lengths, batch_first=True, enforce_sorted=False)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(samples, hidden)\n",
    "        out, out_lens = pad_packed_sequence(out, batch_first=True)\n",
    "        out = self.dropout(out)\n",
    "#         out = out.view(-1, out.shape[-1])\n",
    "        if torch.isnan(out).sum() > 0:\n",
    "            print(f\"NaN in out!\")\n",
    "            raise Exception\n",
    "        tag_logits = self.hidden_to_labels(out)\n",
    "        if pos is not None:\n",
    "            pos_logits = self.hidden_to_pos(out)\n",
    "            return tag_logits, pos_logits\n",
    "        return tag_logits\n",
    "        \n",
    "#         print(f'LENGTHS: {lengths}')\n",
    "#         print(f'LOGITS: {logits.shape}')\n",
    "        \n",
    "#         assert lengths == logits.shape[1]\n",
    "#         logits = logits.permute(0, 2, 1)  \n",
    "        \n",
    "    def _shared_step(self, batch):\n",
    "        ids = batch['id']\n",
    "        tags = batch['tags']\n",
    "        pos = batch['pos']\n",
    "        tag_logits, pos_logits = self(batch)\n",
    "        tag_logits = tag_logits.permute(0, 2, 1)  # must move classes to second dimension\n",
    "        pos_logits = pos_logits.permute(0, 2, 1)\n",
    "#         logger.info(f'TAG shapes: {tags.shape} / {tag_logits.shape}')\n",
    "#         logger.info(f'POS shapes: {pos.shape} / {pos_logits.shape}')\n",
    "        tag_loss = F.cross_entropy(tag_logits, tags, ignore_index=-1)\n",
    "        pos_loss = F.cross_entropy(pos_logits, pos, ignore_index=-1)\n",
    "#         logger.info(f\"TAGS: {tags.shape}\")\n",
    "#         logger.info(f\"LOGITS: {logits.shape}\")\n",
    "#         logits = logits.reshape(-1, logits.shape[-1])\n",
    "#         tags = tags.view(-1)\n",
    "#         logger.info(f\"TAGS: {tags.shape}\")\n",
    "#         logger.info(f\"LOGITS: {logits.shape}\")\n",
    "#         loss = F.nll_loss(F.log_softmax(logits, dim=1), tags, ignore_index=-1)\n",
    "        return tag_loss, pos_loss\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        tag_loss, pos_loss = self._shared_step(batch)\n",
    "        if self.multitask:\n",
    "            tag_weight = self.loss_ratio\n",
    "            pos_weight = 1.0 - self.loss_ratio\n",
    "            loss = ((tag_loss * tag_weight) + (pos_loss * pos_weight))\n",
    "        else:\n",
    "            loss = tag_loss\n",
    "        self.log('training_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        tag_loss, pos_loss = self._shared_step(batch)\n",
    "        loss = tag_loss\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        ids = batch['id']\n",
    "        logits = self(batch)\n",
    "        lengths = batch['length']\n",
    "        self.test_preds['ids'].extend(ids)\n",
    "        self.test_preds['logits'].extend(logits)\n",
    "        self.test_preds['lengths'].extend(lengths)\n",
    "        \n",
    "    def process_logits(self, logits, idx2int):\n",
    "        preds = torch.stack(logits)\n",
    "        preds = preds.argmax(dim=1).tolist()\n",
    "        preds = [idx2int[p] for p in preds]\n",
    "        return preds\n",
    "            \n",
    "    def init_hidden(self, batch_size):\n",
    "#         return torch.normal(mean=0, std=1, size=(self.bidirectional * self.num_layers, batch_size, self.hidden_size)).to('cpu')\n",
    "        return torch.normal(mean=0, std=1, size=(self.bidirectional * self.num_layers, batch_size, self.hidden_size)).to('cuda')\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-14 21:51:29,147 - __main__ - INFO - Loading GloVe embeddings...\n",
      "2021-04-14 21:52:20,476 - __main__ - INFO - Done!\n"
     ]
    }
   ],
   "source": [
    "glove = TaggingPosDataModule._load_glove('../../data/glove.840B.300d.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "declared-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_pos_dm = TaggingPosDataModule(embedding_obj=glove)\n",
    "tag_pos_dm.prepare_data()\n",
    "tag_pos_dm.setup('fit')\n",
    "tag_labels = tag_pos_dm.tag_to_idx\n",
    "pos_labels = tag_pos_dm.pos_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "upset-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask = True\n",
    "model = TaggingPosClassifier(num_labels=len(tag_labels), num_pos=len(pos_labels), lr=1e-4, hidden_size=1024, dropout=0, num_layers=2, loss_ratio=0.75, multitask=multitask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "if multitask:\n",
    "    logging_dir = Path('.').joinpath('tagging_mt_lightning_logs')\n",
    "    filename = 'tagging_mt-{epoch:02d}-{training_loss_epoch:.2f}-{val_loss_epoch:.2f}'\n",
    "else:\n",
    "    logging_dir = Path('.').joinpath('tagging_lightning_logs')\n",
    "    filename = 'tagging-{epoch:02d}-{training_loss_epoch:.2f}-{val_loss_epoch:.2f}'\n",
    "print(str(logging_dir.resolve()))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    filename=filename,\n",
    "    save_top_k=3,\n",
    "    mode='min',\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    \n",
    "#     auto_lr_find=True,\n",
    "    gpus=None,\n",
    "#     gradient_clip_val=1,\n",
    "    weights_summary='full',\n",
    "#     precision=16,\n",
    "#     track_grad_norm=2,\n",
    "    default_root_dir=str(logging_dir.resolve()),\n",
    "#     checkpoint_callback=False\n",
    "    callbacks=[EarlyStopping(monitor='val_loss_epoch'), checkpoint_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-combat",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=tag_pos_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-shadow",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "flexible-nickname",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dclian/adl/hw1/notebooks/tagging_mt_lightning_logs/lightning_logs/version_0/checkpoints/tagging_mt-epoch=13-training_loss=0.03-val_loss=0.09.ckpt'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "specified-maldives",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dclian/adl/hw1/notebooks/tagging_mt_lightning_logs/lightning_logs/version_6/checkpoints/tagging_mt-epoch=28-training_loss_epoch=0.05-val_loss_epoch=0.11.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaggingPosClassifier(\n",
       "  (rnn): GRU(300, 1024, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (hidden_to_labels): Linear(in_features=2048, out_features=9, bias=True)\n",
       "  (hidden_to_pos): Linear(in_features=2048, out_features=58, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_tag_model = TaggingClassifier.load_from_checkpoint('./tagging_lightning_logs/lightning_logs/version_19/checkpoints/epoch=38-step=4445.ckpt')\n",
    "print(checkpoint_callback.best_model_path)\n",
    "best_tag_model = TaggingPosClassifier.load_from_checkpoint(checkpoint_callback.best_model_path)\n",
    "# best_tag_model = TaggingClassifier.load_from_checkpoint('./tagging_lightning_logs/lightning_logs/version_23/checkpoints/tagging-epoch=26-training_loss=0.17-val_loss=0.29.ckpt')\n",
    "best_tag_model.freeze()\n",
    "best_tag_model.to('cuda')\n",
    "\n",
    "# tag_dm = TaggingDataModule(embedding_obj=glove, batch_size=64)\n",
    "# trainer = pl.Trainer(\n",
    "    \n",
    "# #     auto_lr_find=True,\n",
    "#     gpus=1,\n",
    "# #     gradient_clip_val=1,\n",
    "#     weights_summary='full',\n",
    "# #     track_grad_norm=2,\n",
    "# #     default_root_dir=str(logging_dir.resolve()),\n",
    "# #     callbacks=[EarlyStopping(monitor='val_loss')],\n",
    "#     checkpoint_callback=False\n",
    "    \n",
    "# )\n",
    "# trainer.test(best_tag_model, datamodule=tag_dm)\n",
    "# test_preds = best_tag_model.test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "failing-spouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggingPosClassifier(\n",
       "  (rnn): GRU(300, 1024, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (hidden_to_labels): Linear(in_features=2048, out_features=9, bias=True)\n",
       "  (hidden_to_pos): Linear(in_features=2048, out_features=58, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_model = TaggingPosClassifier.load_from_checkpoint('./tagging_mt_lightning_logs/lightning_logs/version_6/checkpoints/tagging_mt-epoch=28-training_loss_epoch=0.05-val_loss_epoch=0.11.ckpt')\n",
    "tag_model.eval()\n",
    "tag_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "opening-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 18, 300])\n",
      "torch.Size([32, 15, 300])\n",
      "torch.Size([32, 24, 300])\n",
      "torch.Size([32, 22, 300])\n",
      "torch.Size([32, 18, 300])\n",
      "torch.Size([32, 17, 300])\n",
      "torch.Size([32, 16, 300])\n",
      "torch.Size([32, 33, 300])\n",
      "torch.Size([32, 22, 300])\n",
      "torch.Size([32, 17, 300])\n",
      "torch.Size([32, 33, 300])\n",
      "torch.Size([32, 22, 300])\n",
      "torch.Size([32, 19, 300])\n",
      "torch.Size([32, 16, 300])\n",
      "torch.Size([32, 21, 300])\n",
      "torch.Size([32, 13, 300])\n",
      "torch.Size([32, 22, 300])\n",
      "torch.Size([32, 18, 300])\n",
      "torch.Size([32, 16, 300])\n",
      "torch.Size([32, 27, 300])\n",
      "torch.Size([32, 26, 300])\n",
      "torch.Size([32, 28, 300])\n",
      "torch.Size([32, 24, 300])\n",
      "torch.Size([32, 30, 300])\n",
      "torch.Size([32, 13, 300])\n",
      "torch.Size([32, 33, 300])\n",
      "torch.Size([32, 26, 300])\n",
      "torch.Size([32, 18, 300])\n",
      "torch.Size([32, 16, 300])\n",
      "torch.Size([32, 21, 300])\n",
      "torch.Size([32, 19, 300])\n",
      "torch.Size([8, 13, 300])\n"
     ]
    }
   ],
   "source": [
    "idx2label = {idx: label for label, idx in tag_labels.items()}\n",
    "tag_pos_dm = TaggingPosDataModule(embedding_obj=glove, batch_size=32)\n",
    "tag_pos_dm.prepare_data()\n",
    "tag_pos_dm.setup(stage='fit')\n",
    "val_dl = tag_pos_dm.val_dataloader()\n",
    "labels = tag_pos_dm.tag_to_idx\n",
    "preds = []\n",
    "for batch in val_dl:\n",
    "    for key, val in batch.items():\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            batch[key] = val.to('cuda')\n",
    "    logits = tag_model(batch)\n",
    "    batch['logits'] = logits\n",
    "    preds.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "amber-tobago",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for batch in preds:\n",
    "    length = batch['length']\n",
    "#     tags = batch['tags']\n",
    "    _id = batch['id']\n",
    "    logits = batch['logits'][0]  # 0 index is tags, 1 is PoS\n",
    "    tags = batch['tags']\n",
    "    num_samples = len(length)\n",
    "    \n",
    "    for sample in range(num_samples):\n",
    "        s_length = length[sample]\n",
    "#         s_tags = tags[sample][:s_length]\n",
    "        s_id = _id[sample][0]\n",
    "        s_logits = logits[sample][:s_length]\n",
    "        print(s_logits.shape)\n",
    "        softmaxed = F.log_softmax(s_logits, dim=1).argmax(dim=1).tolist()\n",
    "#         softmaxed = s_logits.argmax(dim=1).tolist()\n",
    "        print(softmaxed)\n",
    "        gold = [idx2label[i] for i in tags[sample][:s_length].tolist()]\n",
    "        to_tags = [idx2label[i] for i in softmaxed]\n",
    "        \n",
    "        processed.append({\n",
    "            'id': s_id,\n",
    "#             'tags': s_tags,\n",
    "            'length': s_length,\n",
    "            'softmax': softmaxed,\n",
    "            'preds': to_tags,\n",
    "            'gold': gold\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "challenging-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        date       0.81      0.76      0.78       206\n",
      "  first_name       0.94      0.93      0.94       102\n",
      "   last_name       0.85      0.77      0.81        78\n",
      "      people       0.72      0.69      0.70       238\n",
      "        time       0.81      0.80      0.80       218\n",
      "\n",
      "   micro avg       0.80      0.77      0.79       842\n",
      "   macro avg       0.82      0.79      0.81       842\n",
      "weighted avg       0.80      0.77      0.79       842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "preds = [p['preds'] for p in processed]\n",
    "golds = [p['gold'] for p in processed]\n",
    "# print(classification_report([processed[idx]['gold']], [processed[idx]['preds']], scheme=IOB2, mode='strict'))\n",
    "print(classification_report(golds, preds, scheme=IOB2, mode='strict'))\n",
    "# f1_score([processed[idx]['gold']], [processed[idx]['preds']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "resistant-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'B-date', 'I-date', 'I-date']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[4]['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "handled-click",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-334-4090ef1fb744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/adl/lib/python3.8/site-packages/seqeval/metrics/sequence_labeling.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, digits, suffix, output_dict, mode, sample_weight, zero_division, scheme)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mreporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictReporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0mavg_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weighted avg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "y_true = [['O', 'O', 'O']]\n",
    "y_pred = [['O', 'O', 'O']]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "packed-facility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = best_tag_model.process_logits(test_preds['logits'], idx2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fluid-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_pos_dm = TaggingPosDataModule(embedding_obj=glove, batch_size=64)\n",
    "tag_pos_dm.prepare_data()\n",
    "# tag_dm.setup(stage='fit')\n",
    "# val_dl = tag_dm.val_dataloader()\n",
    "tag_pos_dm.setup(stage='test')\n",
    "test_dl = tag_pos_dm.test_dataloader()\n",
    "labels = tag_pos_dm.tag_to_idx\n",
    "test_preds = []\n",
    "for batch in test_dl:\n",
    "    for key, val in batch.items():\n",
    "        if isinstance(val, torch.Tensor):\n",
    "            batch[key] = val.to('cuda')\n",
    "    logits = best_tag_model(batch)\n",
    "    batch['logits'] = logits\n",
    "    test_preds.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "occasional-prophet",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': [['test-0',\n",
       "   'test-0',\n",
       "   'test-0',\n",
       "   'test-0',\n",
       "   'test-0',\n",
       "   'test-0',\n",
       "   'test-0',\n",
       "   'test-0'],\n",
       "  ['test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1',\n",
       "   'test-1'],\n",
       "  ['test-2', 'test-2', 'test-2', 'test-2', 'test-2', 'test-2'],\n",
       "  ['test-3', 'test-3', 'test-3', 'test-3', 'test-3'],\n",
       "  ['test-4', 'test-4', 'test-4', 'test-4'],\n",
       "  ['test-5',\n",
       "   'test-5',\n",
       "   'test-5',\n",
       "   'test-5',\n",
       "   'test-5',\n",
       "   'test-5',\n",
       "   'test-5',\n",
       "   'test-5',\n",
       "   'test-5'],\n",
       "  ['test-6', 'test-6', 'test-6', 'test-6'],\n",
       "  ['test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7',\n",
       "   'test-7'],\n",
       "  ['test-8', 'test-8', 'test-8', 'test-8', 'test-8', 'test-8', 'test-8'],\n",
       "  ['test-9',\n",
       "   'test-9',\n",
       "   'test-9',\n",
       "   'test-9',\n",
       "   'test-9',\n",
       "   'test-9',\n",
       "   'test-9',\n",
       "   'test-9'],\n",
       "  ['test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10',\n",
       "   'test-10'],\n",
       "  ['test-11',\n",
       "   'test-11',\n",
       "   'test-11',\n",
       "   'test-11',\n",
       "   'test-11',\n",
       "   'test-11',\n",
       "   'test-11',\n",
       "   'test-11',\n",
       "   'test-11',\n",
       "   'test-11'],\n",
       "  ['test-12', 'test-12', 'test-12', 'test-12'],\n",
       "  ['test-13', 'test-13', 'test-13', 'test-13'],\n",
       "  ['test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14',\n",
       "   'test-14'],\n",
       "  ['test-15', 'test-15'],\n",
       "  ['test-16', 'test-16', 'test-16'],\n",
       "  ['test-17', 'test-17'],\n",
       "  ['test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18',\n",
       "   'test-18'],\n",
       "  ['test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19',\n",
       "   'test-19'],\n",
       "  ['test-20', 'test-20', 'test-20', 'test-20'],\n",
       "  ['test-21',\n",
       "   'test-21',\n",
       "   'test-21',\n",
       "   'test-21',\n",
       "   'test-21',\n",
       "   'test-21',\n",
       "   'test-21',\n",
       "   'test-21'],\n",
       "  ['test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22',\n",
       "   'test-22'],\n",
       "  ['test-23',\n",
       "   'test-23',\n",
       "   'test-23',\n",
       "   'test-23',\n",
       "   'test-23',\n",
       "   'test-23',\n",
       "   'test-23',\n",
       "   'test-23'],\n",
       "  ['test-24',\n",
       "   'test-24',\n",
       "   'test-24',\n",
       "   'test-24',\n",
       "   'test-24',\n",
       "   'test-24',\n",
       "   'test-24',\n",
       "   'test-24'],\n",
       "  ['test-25', 'test-25', 'test-25', 'test-25', 'test-25', 'test-25'],\n",
       "  ['test-26'],\n",
       "  ['test-27', 'test-27', 'test-27', 'test-27', 'test-27', 'test-27'],\n",
       "  ['test-28', 'test-28', 'test-28', 'test-28', 'test-28'],\n",
       "  ['test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29',\n",
       "   'test-29'],\n",
       "  ['test-30',\n",
       "   'test-30',\n",
       "   'test-30',\n",
       "   'test-30',\n",
       "   'test-30',\n",
       "   'test-30',\n",
       "   'test-30',\n",
       "   'test-30'],\n",
       "  ['test-31',\n",
       "   'test-31',\n",
       "   'test-31',\n",
       "   'test-31',\n",
       "   'test-31',\n",
       "   'test-31',\n",
       "   'test-31'],\n",
       "  ['test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32',\n",
       "   'test-32'],\n",
       "  ['test-33', 'test-33', 'test-33', 'test-33', 'test-33', 'test-33'],\n",
       "  ['test-34', 'test-34', 'test-34', 'test-34'],\n",
       "  ['test-35', 'test-35', 'test-35'],\n",
       "  ['test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36',\n",
       "   'test-36'],\n",
       "  ['test-37', 'test-37', 'test-37', 'test-37', 'test-37'],\n",
       "  ['test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38',\n",
       "   'test-38'],\n",
       "  ['test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39',\n",
       "   'test-39'],\n",
       "  ['test-40',\n",
       "   'test-40',\n",
       "   'test-40',\n",
       "   'test-40',\n",
       "   'test-40',\n",
       "   'test-40',\n",
       "   'test-40'],\n",
       "  ['test-41',\n",
       "   'test-41',\n",
       "   'test-41',\n",
       "   'test-41',\n",
       "   'test-41',\n",
       "   'test-41',\n",
       "   'test-41',\n",
       "   'test-41',\n",
       "   'test-41'],\n",
       "  ['test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42',\n",
       "   'test-42'],\n",
       "  ['test-43', 'test-43', 'test-43', 'test-43', 'test-43', 'test-43'],\n",
       "  ['test-44', 'test-44', 'test-44', 'test-44'],\n",
       "  ['test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45',\n",
       "   'test-45'],\n",
       "  ['test-46',\n",
       "   'test-46',\n",
       "   'test-46',\n",
       "   'test-46',\n",
       "   'test-46',\n",
       "   'test-46',\n",
       "   'test-46',\n",
       "   'test-46',\n",
       "   'test-46'],\n",
       "  ['test-47'],\n",
       "  ['test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48',\n",
       "   'test-48'],\n",
       "  ['test-49'],\n",
       "  ['test-50', 'test-50', 'test-50', 'test-50'],\n",
       "  ['test-51', 'test-51', 'test-51', 'test-51', 'test-51'],\n",
       "  ['test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52',\n",
       "   'test-52'],\n",
       "  ['test-53', 'test-53', 'test-53', 'test-53', 'test-53', 'test-53'],\n",
       "  ['test-54', 'test-54', 'test-54', 'test-54', 'test-54', 'test-54'],\n",
       "  ['test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55',\n",
       "   'test-55'],\n",
       "  ['test-56',\n",
       "   'test-56',\n",
       "   'test-56',\n",
       "   'test-56',\n",
       "   'test-56',\n",
       "   'test-56',\n",
       "   'test-56',\n",
       "   'test-56',\n",
       "   'test-56',\n",
       "   'test-56'],\n",
       "  ['test-57',\n",
       "   'test-57',\n",
       "   'test-57',\n",
       "   'test-57',\n",
       "   'test-57',\n",
       "   'test-57',\n",
       "   'test-57',\n",
       "   'test-57',\n",
       "   'test-57'],\n",
       "  ['test-58', 'test-58', 'test-58'],\n",
       "  ['test-59', 'test-59'],\n",
       "  ['test-60',\n",
       "   'test-60',\n",
       "   'test-60',\n",
       "   'test-60',\n",
       "   'test-60',\n",
       "   'test-60',\n",
       "   'test-60',\n",
       "   'test-60'],\n",
       "  ['test-61', 'test-61', 'test-61'],\n",
       "  ['test-62', 'test-62', 'test-62', 'test-62', 'test-62', 'test-62'],\n",
       "  ['test-63', 'test-63', 'test-63', 'test-63']],\n",
       " 'tokens': tensor([[[ 0.1873,  0.4060, -0.5117,  ...,  0.1649,  0.1876,  0.5387],\n",
       "          [ 0.0652,  0.1469, -0.3010,  ..., -0.2439,  0.3521,  0.2413],\n",
       "          [ 0.0014,  0.3565, -0.0555,  ..., -0.1124,  0.0783,  0.2240],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.2386,  0.3546, -0.3022,  ..., -0.3528,  0.4189,  0.1317],\n",
       "          [ 0.1873,  0.4060, -0.5117,  ...,  0.1649,  0.1876,  0.5387],\n",
       "          [-0.2563,  0.3746, -0.0044,  ..., -0.4401,  0.1595, -0.4015],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.1873,  0.4060, -0.5117,  ...,  0.1649,  0.1876,  0.5387],\n",
       "          [ 0.1494, -0.1722, -0.3959,  ..., -0.6622,  0.1220, -0.2289],\n",
       "          [ 0.0438,  0.0248, -0.2094,  ..., -0.3010, -0.1458,  0.2819],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.1587, -0.1177, -0.5863,  ...,  0.1180, -0.1188, -0.2344],\n",
       "          [-0.0876,  0.3550,  0.0639,  ...,  0.0345, -0.1503,  0.4067],\n",
       "          [-0.0675,  0.5598,  0.3871,  ..., -0.1616, -0.2859,  0.1893],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.1873,  0.4060, -0.5117,  ...,  0.1649,  0.1876,  0.5387],\n",
       "          [-0.0493,  0.2048, -0.1281,  ..., -0.2853,  0.3370,  0.1234],\n",
       "          [-0.1842,  0.0551, -0.3695,  ..., -0.2381,  0.3713,  0.3620],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 0.7935, -0.2117,  0.3591,  ...,  1.1031, -0.6144, -0.8533],\n",
       "          [ 0.6729, -0.3256, -0.2772,  ...,  0.9255, -0.6668, -0.9965],\n",
       "          [ 0.3473,  0.0447,  0.3714,  ..., -0.0599, -0.2281, -0.3388],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "        device='cuda:0'),\n",
       " 'length': tensor([ 8, 12,  6,  5,  4,  9,  4, 15,  7,  8, 12, 10,  4,  4, 21,  2,  3,  2,\n",
       "         22, 11,  4,  8, 11,  8,  8,  6,  1,  6,  5, 12,  8,  7, 22,  6,  4,  3,\n",
       "         21,  5, 11, 17,  7,  9, 11,  6,  4, 18,  9,  1, 14,  1,  4,  5, 23,  6,\n",
       "          6, 17, 10,  9,  3,  2,  8,  3,  6,  4], device='cuda:0'),\n",
       " 'logits': tensor([[[-3.0089e+00, -6.5106e+00, -3.3997e+00,  ..., -8.4921e-01,\n",
       "           -2.9894e+00, -8.3058e+00],\n",
       "          [-2.6745e+00, -6.4764e+00, -1.2620e+00,  ..., -7.0935e-01,\n",
       "           -3.2020e+00, -7.8831e+00],\n",
       "          [-8.0928e+00, -7.2239e+00, -3.4389e+00,  ...,  5.1299e+00,\n",
       "           -1.8996e+00, -9.0458e+00],\n",
       "          ...,\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03]],\n",
       " \n",
       "         [[-3.7554e+00, -5.3926e+00, -1.3025e+00,  ...,  3.1786e-01,\n",
       "            1.5323e+00, -5.7373e+00],\n",
       "          [-4.7201e-01, -6.7863e+00, -3.3860e-01,  ..., -6.8532e-01,\n",
       "           -2.9627e+00, -9.8615e+00],\n",
       "          [-3.4685e+00, -6.9953e+00, -2.4289e+00,  ...,  1.3939e+00,\n",
       "           -3.2271e+00, -8.3476e+00],\n",
       "          ...,\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03]],\n",
       " \n",
       "         [[-1.9205e+00, -5.2877e+00, -3.4906e+00,  ...,  2.2263e-01,\n",
       "           -5.8393e+00, -7.9487e+00],\n",
       "          [-5.9225e+00, -5.5635e+00, -4.2922e+00,  ...,  1.4474e+00,\n",
       "           -4.5319e+00, -7.2937e+00],\n",
       "          [-7.4740e+00, -5.7242e+00, -5.4339e+00,  ...,  2.5869e+00,\n",
       "           -3.8624e+00, -9.3682e+00],\n",
       "          ...,\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-7.1603e+00, -6.7208e-01, -4.4459e+00,  ...,  3.2617e+00,\n",
       "           -6.2998e+00, -5.5855e+00],\n",
       "          [-8.8644e+00,  2.4275e+00, -5.0772e+00,  ...,  1.1027e+01,\n",
       "           -8.7381e-01, -9.3409e+00],\n",
       "          [-8.8809e+00,  1.0397e+01, -1.9615e+00,  ...,  3.0657e+00,\n",
       "           -4.8428e+00, -2.1432e+00],\n",
       "          ...,\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03]],\n",
       " \n",
       "         [[-1.7867e+00, -5.6597e+00, -3.3462e+00,  ..., -2.0678e+00,\n",
       "           -4.6536e+00, -6.8409e+00],\n",
       "          [-2.8500e+00, -7.5538e+00, -3.0285e+00,  ..., -5.3536e-01,\n",
       "           -4.8292e+00, -6.8301e+00],\n",
       "          [-5.0797e+00, -9.2525e+00, -4.3112e+00,  ...,  2.5041e+00,\n",
       "           -2.5174e+00, -8.8203e+00],\n",
       "          ...,\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03]],\n",
       " \n",
       "         [[-2.3278e+00, -5.3386e+00,  4.0359e-01,  ..., -5.7918e+00,\n",
       "           -2.8442e+00, -4.4868e+00],\n",
       "          [-3.4033e+00, -6.9049e+00,  1.7895e+00,  ..., -4.1588e+00,\n",
       "            2.9723e-01, -7.0395e+00],\n",
       "          [-4.4637e+00, -7.5582e+00,  2.5158e+00,  ..., -1.2343e+00,\n",
       "            1.2610e+01, -8.8917e+00],\n",
       "          ...,\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03],\n",
       "          [-1.3224e-02,  9.5561e-03, -1.7509e-03,  ...,  9.2548e-03,\n",
       "           -1.8312e-02, -4.6124e-03]]], device='cuda:0')}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "proprietary-haven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'tokens', 'length', 'logits'])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "angry-switch",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 23, 9])\n",
      "64\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 27, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([27, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([64, 28, 9])\n",
      "64\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([28, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([64, 24, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([64, 26, 9])\n",
      "64\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([26, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 24, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 29, 9])\n",
      "64\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([29, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([64, 20, 9])\n",
      "64\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([64, 22, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 21, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([64, 16, 9])\n",
      "64\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([64, 18, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([64, 30, 9])\n",
      "64\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([30, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([64, 23, 9])\n",
      "64\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([64, 35, 9])\n",
      "64\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([25, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([35, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([64, 21, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([64, 24, 9])\n",
      "64\n",
      "torch.Size([9, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([64, 23, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([64, 20, 9])\n",
      "64\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 20, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([64, 21, 9])\n",
      "64\n",
      "torch.Size([14, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([64, 30, 9])\n",
      "64\n",
      "torch.Size([22, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([30, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 22, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([64, 26, 9])\n",
      "64\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([25, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([26, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([64, 19, 9])\n",
      "64\n",
      "torch.Size([1, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([64, 18, 9])\n",
      "64\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([64, 24, 9])\n",
      "64\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 28, 9])\n",
      "64\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([26, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([28, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([64, 20, 9])\n",
      "64\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([64, 22, 9])\n",
      "64\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([64, 27, 9])\n",
      "64\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([27, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([64, 18, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([64, 35, 9])\n",
      "64\n",
      "torch.Size([16, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([35, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([64, 26, 9])\n",
      "64\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([26, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([64, 18, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([64, 25, 9])\n",
      "64\n",
      "torch.Size([17, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([25, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([64, 21, 9])\n",
      "64\n",
      "torch.Size([14, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([64, 24, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 34, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([34, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 35, 9])\n",
      "64\n",
      "torch.Size([12, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([35, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([25, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 23, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([64, 18, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 19, 9])\n",
      "64\n",
      "torch.Size([1, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([64, 19, 9])\n",
      "64\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 32, 9])\n",
      "64\n",
      "torch.Size([4, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([32, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([64, 24, 9])\n",
      "64\n",
      "torch.Size([8, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 20, 9])\n",
      "64\n",
      "torch.Size([3, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 19, 9])\n",
      "64\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 29, 9])\n",
      "64\n",
      "torch.Size([18, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([29, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([64, 21, 9])\n",
      "64\n",
      "torch.Size([14, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([64, 27, 9])\n",
      "64\n",
      "torch.Size([7, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([27, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 25, 9])\n",
      "64\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([25, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([64, 21, 9])\n",
      "64\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([64, 27, 9])\n",
      "64\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([23, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([27, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([64, 16, 9])\n",
      "64\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([64, 22, 9])\n",
      "64\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([19, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([18, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([64, 26, 9])\n",
      "64\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([17, 9])\n",
      "torch.Size([22, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([26, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([13, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([64, 25, 9])\n",
      "64\n",
      "torch.Size([18, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([21, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([25, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([14, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([24, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([6, 9])\n",
      "torch.Size([20, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([16, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([1, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([12, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([15, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([19, 11, 9])\n",
      "19\n",
      "torch.Size([6, 9])\n",
      "torch.Size([3, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([11, 9])\n",
      "torch.Size([4, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([5, 9])\n",
      "torch.Size([8, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([2, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([7, 9])\n",
      "torch.Size([9, 9])\n",
      "torch.Size([10, 9])\n",
      "torch.Size([5, 9])\n"
     ]
    }
   ],
   "source": [
    "processed_test = []\n",
    "for batch in test_preds:\n",
    "    length = batch['length']\n",
    "#     tags = batch['tags']\n",
    "    _id = batch['id']\n",
    "    logits = batch['logits']\n",
    "    print(logits.shape)\n",
    "    num_samples = len(length)\n",
    "    print(num_samples)\n",
    "    \n",
    "    for sample in range(num_samples):\n",
    "        s_length = length[sample]\n",
    "#         s_tags = tags[sample][:s_length]\n",
    "        s_id = _id[sample][0]\n",
    "        s_logits = logits[sample][:s_length]\n",
    "        print(s_logits.shape)\n",
    "        softmaxed = F.log_softmax(s_logits, dim=1).argmax(dim=1).tolist()\n",
    "#         softmaxed = s_logits.argmax(dim=1).tolist()\n",
    "        to_tags = [idx2label[i] for i in softmaxed]       \n",
    "        \n",
    "        processed_test.append({\n",
    "            'id': s_id,\n",
    "#             'tags': s_tags,\n",
    "            'length': s_length,\n",
    "            'softmax': softmaxed,\n",
    "            'preds': to_tags\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "informational-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_NO = 'version_6'\n",
    "if multitask:\n",
    "    with open(f'../preds/slot_mt_preds_{VERSION_NO}.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'tags'])\n",
    "        for p in processed:\n",
    "            _id = p['id']\n",
    "            tags = \" \".join(p['preds'])\n",
    "            writer.writerow([_id, tags])\n",
    "else:\n",
    "    with open(f'../preds/slot_preds_{VERSION_NO}.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['id', 'tags'])\n",
    "        for p in processed:\n",
    "            _id = p['id']\n",
    "            tags = \" \".join(p['preds'])\n",
    "            writer.writerow([_id, tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "discrete-participation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'test-20',\n",
       " 'length': tensor(4, device='cuda:0'),\n",
       " 'softmax': [4, 6, 1, 1],\n",
       " 'preds': ['O', 'B-date', 'I-date', 'I-date']}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "piano-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 59/59 [00:02<00:00, 27.92it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=tag_pos_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fatty-brick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 9])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_preds['logits'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "touched-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ADL21-HW1/data/slot/eval.json') as f:\n",
    "    ev = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "identical-technician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': ['i', 'prefer', 'a', 'table', 'outdoors'],\n",
       " 'tags': ['O', 'O', 'O', 'O', 'O'],\n",
       " 'id': 'eval-0'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "located-thumb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-01 12:56:35,385 - __main__ - INFO - Intent predictions written to ../ADL21-HW1/data/slot/slot_preds.csv\n"
     ]
    }
   ],
   "source": [
    "write_preds_to_csv(task='tagging', ids=list(chain.from_iterable(test_preds['ids'])), preds=predictions, fpath='../ADL21-HW1/data/slot/slot_preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bound-testing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-people': 0,\n",
       " 'I-date': 1,\n",
       " 'B-last_name': 2,\n",
       " 'B-time': 3,\n",
       " 'O': 4,\n",
       " 'B-people': 5,\n",
       " 'B-date': 6,\n",
       " 'B-first_name': 7,\n",
       " 'I-time': 8}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "aggregate-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ADL21-HW1/data/slot/test.json') as f:\n",
    "    test = json.load(f)\n",
    "with open('../ADL21-HW1/data/slot/slot_preds.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    preds = [row[1] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-realtor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "casual-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = []\n",
    "for idx, (pred, t) in enumerate(zip(preds, test)):\n",
    "    if len(t['tokens']) != len(pred.split()):\n",
    "        idxs.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "basic-loading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "aging-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'i', 'book', 'a', 'outside', 'table', 'for', '3', 'days', 'for', '11:30', 'am'] 12\n",
      "B-first_name B-first_name B-first_name B-first_name B-first_name B-first_name B-first_name B-first_name B-first_name B-first_name B-first_name B-first_name 12\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(test[i]['tokens'], len(test[i]['tokens']))\n",
    "print(preds[i], len(preds[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "sudden-compact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'want', 'it', 'for', '4', 'people', 'at', '10:30am']\n",
      "O O O O B-people I-people O O\n",
      "['can', 'i', 'book', 'a', 'outside', 'table', 'for', '3', 'days', 'for', '11:30', 'am']\n",
      "O O O O O O O O O O O O\n",
      "['i', 'require', 'a', 'table', 'for', '13']\n",
      "O O O O O O\n",
      "['do', 'you', 'have', 'disabled', 'access']\n",
      "O O O O B-time\n",
      "['last_name', 'first_name', 'joseph', 'vitello']\n",
      "I-time O B-time O\n",
      "['people', 'how', 'about', '2', 'of', 'us', 'and', 'seated', 'together']\n",
      "O O O O O O O O O\n",
      "['people', 'for', 'three', 'people']\n",
      "O O O O\n",
      "['i', 'am', 'calling', 'to', 'make', 'a', 'cancellation', 'i', 'booked', 'it', 'under', 'the', 'name', 'junko', 'takeshita']\n",
      "O O O B-time O O O O O O O O O O O\n",
      "['i', 'am', 'booked', 'for', 'thursday', 'aug', '30th']\n",
      "O O O O O O O\n",
      "['i', 'need', 'seating', 'on', 'sun', '19', 'aug', '2018']\n",
      "O O O O O O O O\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(test[i]['tokens'])\n",
    "    print(preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "applied-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"I like cats.\"\n",
    "s2 = \"What's for dinner tonight?\"\n",
    "s3 = \"What have you been up to lately?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smaller-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I, like, cats, .] 4\n",
      "[What, 's, for, dinner, tonight, ?] 6\n",
      "[What, have, you, been, up, to, lately, ?] 8\n"
     ]
    }
   ],
   "source": [
    "nlp = English()\n",
    "tokenizer = nlp.tokenizer\n",
    "tokens = []\n",
    "lengths = []\n",
    "# for s in nlp.pipe([s1, s2, s3], disable=['tagger', 'parser', 'ner', 'textcat']):\n",
    "for s in [s1, s2, s3]:\n",
    "    toks = list(tokenizer(s))\n",
    "    print(toks, len(toks))\n",
    "    toks = [torch.from_numpy(glove.get(t.text)).float() for t in toks]\n",
    "    lengths.append(len(toks))\n",
    "    tokens.append(torch.stack(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floppy-orleans",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 300])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "joint-burden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8, 300])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = pad_sequence(tokens, batch_first=True)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lesbian-holly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.2063,  0.3672, -0.0719,  ...,  0.1427,  0.5006,  0.0380],\n",
       "        [-0.2063,  0.3672, -0.0719,  ...,  0.1427,  0.5006,  0.0380],\n",
       "        [ 0.1941,  0.2260, -0.4376,  ...,  0.0920,  0.3863,  0.1174],\n",
       "        ...,\n",
       "        [-0.0869,  0.1916,  0.1091,  ..., -0.0152,  0.1111,  0.2065],\n",
       "        [-0.1847, -0.0507, -0.2266,  ..., -0.4082, -0.2069, -0.1493],\n",
       "        [-0.0869,  0.1916,  0.1091,  ..., -0.0152,  0.1111,  0.2065]]), batch_sizes=tensor([3, 3, 3, 3, 2, 2, 1, 1]), sorted_indices=tensor([2, 1, 0]), unsorted_indices=tensor([2, 1, 0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed = pack_padded_sequence(padded, batch_first=True, lengths=lengths, enforce_sorted=False)\n",
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lonely-george",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 20])\n",
      "torch.Size([3, 8, 40])\n",
      "torch.Size([3, 5, 8])\n",
      "torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "gru = nn.GRU(300, 20, batch_first=True, num_layers=3, bidirectional=True)\n",
    "to_labels = nn.Linear(40, 5)\n",
    "v = torch.randn(3, 10, 5)\n",
    "y = torch.randint(high=5, size=(3, 10))\n",
    "out, hidden = gru(packed)\n",
    "print(hidden.shape)\n",
    "out, out_lens = pad_packed_sequence(out, batch_first=True)\n",
    "print(out.shape)\n",
    "out = to_labels(out)\n",
    "out = out.permute(0, 2, 1)\n",
    "print(out.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "awful-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "repad = pad_packed_sequence(out, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "talented-jimmy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5605e-01, -2.6099e-01, -3.0838e-02,  1.2341e-01, -4.4563e-02,\n",
       "          3.2513e-02, -6.6367e-02, -4.4984e-02, -1.7640e-01,  1.4038e-01,\n",
       "          1.2488e-01, -1.9052e-02,  9.4344e-02,  8.7463e-02,  6.5304e-02,\n",
       "         -6.2826e-02,  5.3467e-02,  2.0741e-01,  5.1490e-02,  6.2634e-02,\n",
       "         -2.4891e-01,  7.0459e-02,  1.0758e-01,  1.4629e-01, -5.3113e-02,\n",
       "          1.9575e-03, -4.0004e-01, -7.4937e-02, -1.1238e-01, -8.9180e-02,\n",
       "         -2.9598e-01, -1.8928e-01, -2.0572e-01, -1.9954e-01, -1.1982e-01,\n",
       "         -2.6132e-01,  2.0621e-01,  3.0803e-01, -9.3074e-02, -9.0306e-02],\n",
       "        [ 2.2690e-01, -3.9751e-01, -2.5597e-02,  1.4637e-01, -1.6102e-02,\n",
       "          3.1110e-02, -9.2124e-02, -1.1040e-01, -2.9708e-01,  2.5622e-01,\n",
       "          1.6872e-01,  2.1500e-02,  2.1497e-01,  1.7024e-01,  1.6807e-01,\n",
       "         -6.2749e-02,  7.9430e-02,  3.6981e-01,  1.8130e-02,  7.4128e-02,\n",
       "         -1.6896e-01,  6.5061e-02,  1.6951e-01,  1.5283e-01, -2.8648e-02,\n",
       "         -3.7681e-02, -3.2653e-01, -2.7124e-02, -1.4534e-01, -6.0098e-02,\n",
       "         -2.0966e-01, -2.0279e-01, -1.9247e-01, -1.5274e-01, -1.1368e-01,\n",
       "         -2.1131e-01,  2.4846e-01,  2.6269e-01, -1.0981e-02, -1.1321e-01],\n",
       "        [ 2.7246e-01, -4.5401e-01, -1.9300e-02,  1.0473e-01,  1.8407e-02,\n",
       "          3.3396e-02, -1.1301e-01, -1.7913e-01, -3.4312e-01,  2.8010e-01,\n",
       "          1.0007e-01,  7.7245e-02,  3.2600e-01,  2.3057e-01,  2.3472e-01,\n",
       "         -2.5004e-02,  9.4340e-02,  5.0567e-01, -5.3118e-02,  8.2006e-02,\n",
       "         -9.7242e-02,  6.9880e-02,  1.8840e-01,  1.4532e-01, -7.0441e-03,\n",
       "         -7.9246e-02, -2.3397e-01,  1.7296e-02, -1.7401e-01, -6.3260e-02,\n",
       "         -1.4565e-01, -2.0787e-01, -1.4312e-01, -7.8237e-02, -9.8075e-02,\n",
       "         -1.4705e-01,  2.6236e-01,  2.1762e-01,  6.5243e-02, -8.1177e-02],\n",
       "        [ 2.8669e-01, -4.3982e-01, -1.1221e-01,  3.3460e-02,  4.1583e-02,\n",
       "          2.4739e-02, -8.3042e-02, -2.0435e-01, -3.0141e-01,  2.6525e-01,\n",
       "          6.5915e-05,  7.3606e-02,  3.2124e-01,  2.2519e-01,  2.6809e-01,\n",
       "          1.5640e-03,  1.3346e-01,  5.7178e-01, -1.0264e-01,  8.3069e-02,\n",
       "         -6.5156e-02,  7.0771e-02,  1.2868e-01,  1.2322e-01,  4.2480e-02,\n",
       "         -3.5036e-02, -1.2530e-01,  3.5030e-02, -1.2631e-01, -3.2963e-02,\n",
       "         -7.5305e-02, -1.2804e-01, -7.5549e-02, -4.9326e-02, -4.8324e-02,\n",
       "         -5.3735e-02,  1.5049e-01,  1.7601e-01,  6.5513e-02, -4.5579e-02]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repad[0][0,:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "medical-clearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 2\n",
    "missing = 0\n",
    "l = [1, 2, 3, 4, 5, 6, 7]\n",
    "print(f\"MISSING: {l[missing]}\")\n",
    "l[max(missing-window, 0):missing] + l[missing + 1: missing+1+window]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "purple-assumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.stack([torch.rand(10) if np.random.choice([1, 0]) else torch.zeros(10) for i in range(5)])\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "choice-mechanism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[l.nonzero(as_tuple=True)].view(-1, l.shape[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sudden-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.rand(2, 10), dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "motivated-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0579, 0.1714, 0.8727, 0.9940, 0.8213, 0.2101, 0.7483, 0.0440, 0.3493,\n",
       "         0.7820]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[1:3] + l[3: 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "closed-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one(l):\n",
    "    l.append(1)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dental-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_one([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "otherwise-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.FloatTensor([\n",
    "    [10, 100, 1, 3],\n",
    "    [100, 5, 101, 4],\n",
    "    [1, 2, 3, 100],\n",
    "    [10, 12, 100, 1],\n",
    "    [100, 1, 2, 3],\n",
    "    [200, 300, 1, 500]\n",
    "])\n",
    "y = y.unsqueeze(0)\n",
    "y = y.repeat(2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "homeless-breakfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cross-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.LongTensor([\n",
    "    1, 2, 3, 2, 0, -1\n",
    "])\n",
    "y_hat = y_hat.unsqueeze(0)\n",
    "y_hat = y_hat.repeat(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aware-romance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0627)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(y.view(-1, 4), y_hat.view(-1), ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fresh-republican",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "brown-layout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 4])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.repeat(2, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "anonymous-foster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  2,  0, -1],\n",
       "        [ 1,  2,  3,  2,  0, -1]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "interesting-treasury",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "if any().repeat(1):\n",
    "    print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "modern-journal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(torch.tensor([1, float('nan'), 2])).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "severe-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [2, 1],\n",
    "    [0, 3]\n",
    "])\n",
    "M = np.array([\n",
    "    [3, 4],\n",
    "    [2, 0]\n",
    "])\n",
    "M_inv = np.linalg.inv(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "minute-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3.])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "analyzed-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 3.])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(M_inv @ A @ M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "widespread-authority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.  ,  0.  ],\n",
       "       [-0.25,  2.  ]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_inv @ A @ M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "simplified-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../ADL21-HW1/data/slot/train.json') as f:\n",
    "    train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "grave-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = train[5448]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-nepal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "adl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
